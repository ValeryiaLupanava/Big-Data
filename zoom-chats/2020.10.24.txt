11:03:43	 From Елена : Как тест найти?
11:09:17	 From Viktor Gurov : всем привет - уже начали? 
11:09:21	 From Viktor Gurov : опоздал
11:09:49	 From Petr Ermakov : Тест начали
11:10:03	 From Oleg Agapov : Все кто пришел на модуль ML, добавьтесь плиз в канал #module-ml в слаке
11:20:31	 From Aleksandr : http://www.machinelearning.ru/wiki/images/5/53/Mel_lain_msu_nlp_sem_1.pdf
11:21:51	 From Aleksandr : Вот там внутриСтэмминг — процесс приведения слова к основе (отрезаниеокончания и формообразующего суффикса), грубо, но быстро.I Porter stemmerI Snowball stemmerI Lancaster stemmerЛемматизация — процесс приведения слова к нормальнойформе, качественно, но долго.I pymorphy2 (язык русский, украинский)
11:28:31	 From Aleksandr : По поводу второго вопроса - я не очень понял. Там же вроде нигде не сказано, что других документов нет. Поэтому IDF может для этих слов быть разным, если есть еще документы. Разве нет?
11:30:47	 From valeryialupanava : Дмитрий насмешил))))
11:36:44	 From Семён Шафронов : У тебя классная аппаратура. Наушники, фильтр. Как будто ди-джей на радио)
11:39:05	 From Михаил Новиков : а какже пальцы в розетку сунуть :)
11:43:02	 From allburn : ))
11:50:14	 From Михаил Новиков : задать колво кучек всеже придется...
11:52:15	 From Семён Шафронов : Марио!
11:54:46	 From Viktor Gurov : buy/selll
11:54:51	 From Максим Кобзев : М/Ж
11:54:52	 From Viktor Gurov : loan/deposit
11:54:52	 From Семён Шафронов : У меня на работе: сомнительный платеж или нет.
11:55:01	 From Dmitry Novikov : Хот-дог - не хот-дог (теория большого взрыва)
11:55:12	 From Марина Капуш : Выйдет на просрочку илинет
11:55:13	 From Катерина Кучерявенко : рисковый дефолт
11:56:21	 From Viktor Gurov : black/white
11:58:24	 From Petr Ermakov : -------
11:58:55	 From Viktor Gurov : USD/RUB/EUR/JPY
11:59:07	 From Катерина Кучерявенко : документы по типам назначения
11:59:09	 From Viktor Gurov : сделки по валюте
11:59:17	 From Михаил Новиков : распознование типа дефектов  гдето...
11:59:27	 From Ruslan Tskhovrebadze : Категория клиента - молодежь/взрослый/пенсионер
11:59:59	 From Viktor Gurov : йена
12:02:47	 From Михаил Новиков : крестик
12:02:49	 From Ruslan Tskhovrebadze : Крестик
12:02:50	 From Денис Маркин : x
12:02:51	 From Dmitry Vorobyev : крестик
12:02:51	 From Семён Шафронов : крестик
12:02:52	 From Natalya : крестик
12:02:52	 From Semyon Bochkaryov : X
12:02:53	 From Константин Иванченко : Крестик
12:05:00	 From Viktor Gurov : отлично
12:05:04	 From Viktor Gurov : темп
12:05:10	 From Ruslan Tskhovrebadze : Норм )
12:06:43	 From Михаил Новиков : областью например
12:11:39	 From Alexander Dorofeyev : на Kaggle как раз кейс с Титаником выложен и уже за сотню решений
12:12:12	 From Семён Шафронов : И предсказание диабета у индейцев - тоже классика)
12:14:07	 From Petr Ermakov : ---------
12:14:08	 From Dmitry Novikov : По температуре и давлению предсказать влажность
12:14:20	 From Максим Кобзев : спрос
12:14:28	 From Dmitry Novikov : курс валюты :)
12:14:29	 From Марина Капуш : Цена акции
12:14:29	 From Галина Малютина : скор балл клиента 
12:14:48	 From vasanya : стоимость недвижимости
12:15:02	 From Dmitry Pyshkin : Предсказать посещаемость торгового центра
12:15:19	 From Semyon Bochkaryov : Дорожный трафик в зависимости от времени и места
12:15:25	 From allburn : рейтинг фильма на imdb
12:15:32	 From Sergey Efimenko : количество и сумма выплат по полису
12:16:28	 From Михаил Новиков : но ведь в задачах классификации тоже регрессия используется.... где нужно определить класс
12:19:21	 From Максим Кобзев : Зависит от кол-ва классов
12:21:51	 From Dmitry Novikov : Можно найти средний возраст группы и перейти от номера группы к возрасту.
12:24:17	 From Sergey Efimenko : если в вашей системе координат школьники похожи на пенсионеров (например, не ходят на работу, мало денег), до регрессия может дать некорректный ответ
12:25:10	 From Alexander Dorofeyev : А почему мы гворим, что разделяющая плоскость может быть только одна? Как раз, как правило, их несколько
12:32:49	 From Dmitry Vorobyev : Коробочка - это алгоритм МЛ?
12:34:26	 From Марина Капуш : Нужна метрика
12:34:34	 From Dmitry Vorobyev : Ну видимо проверить кусками
12:34:37	 From Ruslan Tskhovrebadze : Проверить на исходных данных
12:35:05	 From andreychubin : MSE
12:35:21	 From Павел Минькин : AB тест
12:35:34	 From Dmitry Vorobyev : 5 мин
12:36:17	 From Михаил Новиков : f1 
12:36:22	 From Petr Ermakov : ----------------
12:36:30	 From Alex Softwarer : модете таймер немного сдвинуть?
12:36:58	 From Dmitry Vorobyev : Пока хочу сказать спасибо что полочкам и все и медленно. Сколько не брал туториалов по МЛ сразу начинается с жести
12:37:03	 From Михаил Новиков : нужно ли нормализовать данные перед регрессией чтобы std по выборке был 0?
12:37:13	 From Семён Шафронов : В начале лекции было сказано про то, что модели можно дообучать. Об этом будет рассказано в следующих лекциях?
12:42:13	 From Михаил Новиков : тоже хочу узнать по какиенибудь самообучаемые модели в процессе получения новых входящих данных
12:42:52	 From Petr Ermakov : Мне нужно перегрузить комп, продолжаем лекцию в 12,45
12:48:32	 From Семён Шафронов : Будет дальше рассказано о средствах работы с перекошенными выборками?
12:48:46	 From Михаил Новиков : нужна ли подготовка данных для модели
12:49:51	 From Dmitry Vorobyev : А что значит нормировать данные?
12:53:02	 From Семён Шафронов : Палец вверх за анимацию)
12:54:49	 From Dmitry Vorobyev : отклонение
12:58:16	 From Марина Капуш : производные
13:01:08	 From Марина Капуш : Более явно видна ошибка
13:06:39	 From Павел Минькин : MSE - это дисперсия? А rmse - среднеквад.откл?
13:08:06	 From Семён Шафронов : В чем преимущество RMSE перед MSE, если и то и другое плохо интерпретируемо?
13:08:44	 From Dmitry Vorobyev : А почему так важен этот минимум, о котором ты говоришь?
13:08:59	 From Семён Шафронов : Спасибо:)
13:09:46	 From Александр Бобр : Дмитрий, я так понимаю, потому что нам нужно минимальную ошибку найти
13:10:00	 From Dmitry Vorobyev : Тоже так подумал, но решил уточнить
13:10:57	 From Dmitry Novikov : 50, 50
13:11:32	 From Aleksandr : 50, 50
13:11:36	 From Viktor Gurov : согласен 
13:11:40	 From Алексей : 50/50
13:12:25	 From Dmitry Vorobyev : На 100 конечно важнее
13:12:27	 From Viktor Gurov : в первом случае
13:12:28	 From Семён Шафронов : В цене на 100
13:13:32	 From Viktor Gurov : а что делает логарифм? (тупой вопрос)
13:13:56	 From Viktor Gurov : в данном случае
13:14:03	 From Viktor Gurov : ок
13:14:17	 From Aleksandr : ~0.175, 0.00216
13:14:17	 From Dmitry Novikov : 0.175  0.002
13:14:28	 From Алексей : Логарифм нормирует на величину стоимости.
13:15:28	 From Viktor Gurov : 8
13:15:42	 From Viktor Gurov : 3
13:16:49	 From Viktor Gurov : ок
13:18:30	 From Dmitry Vorobyev : Вот да
13:18:33	 From Dmitry Novikov : Что на счёт вычислительной сложности?
13:18:40	 From Алексей : даёт отрицательные значения
13:18:42	 From Tanya : не подходит для отрицательных чисел
13:18:46	 From Алексей : <1
13:18:49	 From Марина Капуш : На числах от 0 до 1
13:18:51	 From Максим Кобзев : Если есть нули
13:19:10	 From Viktor Gurov : 0
13:19:31	 From Катерина Кучерявенко : 0
13:19:57	 From Dmitry Vorobyev : Так и в чем жеппа?
13:21:00	 From Dmitry Vorobyev : Получается, что если все положительное, то предпочтительнее рмсле, иначе рмсе
13:21:20	 From Михаил Новиков : градусы приведя к кельвинам можно предсказать :)
13:24:47	 From Alexander Dorofeyev : категорически не согласен с заявлением, но ладно
13:26:07	 From Dmitry Novikov : Александр, +1 
13:26:27	 From Алексей : Отчасти, но бывают сильно разные пространства состояний.
13:27:07	 From Alexander Dorofeyev : ок ))сорри еще раз
13:29:20	 From Sergey Efimenko : цена метра
13:30:55	 From Алексей : 0
13:30:56	 From Марина Капуш : 0
13:30:56	 From Aleksandr : 0
13:32:01	 From Михаил Новиков : прямой пример ложной регресии
13:32:11	 From Dmitry Novikov : А если в модель ML включить имя клиента, то при выдаче ипотеки по этой модели все "Иваны" будут чаще получать отказ, чем все остальные люди :(
13:33:04	 From Alexander Dorofeyev : Это нарушает закон о банках ))
13:34:06	 From Sergey Efimenko : важные
13:34:35	 From Алексей : Важно соотношения длины и ширины.
13:34:46	 From Алексей : Тоже неплохо, почти также как и площадь.
13:34:47	 From Dmitry Novikov : Квартиры, в которых все комнаты -корридоры :)
13:35:47	 From Dmitry Novikov : От станции метро лучше
13:36:05	 From Sergey Efimenko : пока не пересечем границу мо
13:37:14	 From Алексей : Рублёвка.
13:37:20	 From Dmitry Vorobyev : То есть алгоритму нужна какая-то прямая зависимость, он эти фичи на регионы делить не умеет?
13:38:42	 From Dmitry Vorobyev : Да, уже овтетили
13:39:14	 From Alexander Dorofeyev : Т.е. DS должен разбираться в предмете, а не просто ворочать данными )
13:39:49	 From Dmitry Vorobyev : То есть это DS как раз разбирается при подготовке, есть ли прямая зависимость или нет. Я правильно понял?
13:40:28	 From Михаил Новиков : бывает еще и собрать
13:41:00	 From Dmitry Vorobyev : 4
13:41:20	 From Семён Шафронов : Хуже.
13:41:21	 From Aleksandr : Хуже
13:41:23	 From Dmitry Vorobyev : Ну это идеально по картинке
13:41:28	 From Dmitry Vorobyev : Но предчувствие плохое
13:41:29	 From Sergey Efimenko : переобучена
13:42:56	 From Dmitry Vorobyev : Видимо как-то нужно эту ошибку оценить
13:43:03	 From Марина Капуш : На новой выборке проверить качество
13:43:52	 From Sergey Efimenko : откуда мы знаем, что есть плохо
13:44:12	 From Семён Шафронов : Выбросы выбросить.
13:44:33	 From Александр Бобр : Сергей у нас выборка, на которой мы обучаем, уже определены параметры. Как в проекте например - есть записи где пол и возраст уже определены.
13:45:02	 From Александр Бобр : Соответственно на этих записях учим модель, и проверяем совпали ли рзультаты от модели с реальными параметрами
13:45:08	 From Александр Бобр : Как я понимаю, опять же
13:45:13	 From Михаил Новиков : делать мутацию данных...  увеличить выборку...
13:45:18	 From Sergey Efimenko : Александр, мы не знаем, какая точност достижима
13:45:54	 From Sergey Efimenko : структура данных может бытть такова, что высокую точность не достичь
13:45:59	 From Александр Бобр : Ну мы стараемся достичь максимальной)
13:46:27	 From Dmitry Vorobyev : Но получается нужно трейл данные тоже как-то репрезентативно выбирать? Как такие подобрать? Или неважно?
13:46:41	 From Dmitry Vorobyev : трейн* данные
13:47:00	 From Марина Капуш : Мы будем разбирать ситуацию, когда классы (1;0) очень несбалансированы и мы не можем позволить себе разбить на train и test?
13:47:23	 From Александр Бобр : В матстате есть вроде методы составления репрезентативной выборки из ГС
13:47:27	 From Александр Бобр : ПРостые
13:48:49	 From Alexander Dorofeyev : Требования к точности задает бизнес-заказчик (если может)
13:49:26	 From Александр Бобр : "Бизнес"-заказчик обычно говорит "хочу абсолютно точно"
13:49:40	 From Dmitry Novikov : Хотеть не вредно :)
13:49:54	 From Alexander Dorofeyev : Тут начинается работа Product Manager )
13:50:05	 From Катерина Кучерявенко : в каком соотношении лучше разбивать данный на трейн и тест?
13:50:06	 From Sergey Efimenko : иногда заранее известна структура случайной ошибки, например, пуассоновская или нормальная. 
13:50:28	 From Sergey Efimenko : минимизировать относительно определенного уровня нельзя
13:50:39	 From Алексей : 80/20?
13:51:13	 From Семён Шафронов : Можно ли проверить переобучение не через разбиение на train/test, а через удаление выбросов в train-выборке и сравнение точности до- и после удаления выбросов?
13:51:42	 From Sergey Efimenko : выбросы нужно еще найти
13:51:55	 From Михаил Новиков : можно уменьшить переобучение через мутацию данных...
13:53:45	 From Марина Капуш : Крос валидация
13:56:21	 From Tanya : мы в этом случае выбираем только модель но не коэффициенты?
13:56:56	 From Ruslan Tskhovrebadze : А какая коробочка берется в итоге?
13:58:53	 From Михаил Новиков : нууу это уже ансамбль
13:59:37	 From Ruslan Tskhovrebadze : Да, спасибо!
14:01:02	 From Семён Шафронов : Насколько корректно после к-fold-validation обучать модель на всей выборке? Ведь мы не проверяем качество предсказания всей выборки. Мы не знаем, как она себя поведет. 
14:01:37	 From Dmitry Novikov : https://optuna.org/#code_examples
14:02:46	 From Семён Шафронов : Спасибо. Понял.
14:08:08	 From Семён Шафронов : Все понятно
14:09:17	 From Максим Кобзев : Не понял где в правиле 3 П собственно 3 П
14:12:00	 From Михаил Новиков : f
14:12:01	 From Ruslan Tskhovrebadze : В комбинации
14:13:27	 From Алексей : Когда всё включено.
14:20:58	 From Семён Шафронов : Можно ли использовать только recall, если стоит задача уменьшить количество ложноположительных срабатываний модели при обработке платежей? Т.е. важно не пропустить ни одного плохого платежа, но по возможности сократить количество хороших платежей, классифицированных как плохие.
14:21:41	 From Семён Шафронов : Точнее, precision )
14:21:58	 From Viktor Gurov : Надо бежать , Спасибо огромное!
14:23:03	 From Михаил Новиков : было интересно
14:24:12	 From Олег Резниченко : очень интересно, большое спасибо за лекцию
14:24:23	 From Tanya : спасибо!
14:24:23	 From Ruslan Tskhovrebadze : Да, лекция крутая
14:24:28	 From Екатерина Назарова : Спасибо! 
14:24:29	 From Dmitry Novikov : Спасибо большое :)
14:24:31	 From Марина Капуш : Спасибо :) все понятно и просто
14:24:55	 From Катерина Кучерявенко : спасибо) еще доступно и структурировано
14:24:57	 From Семён Шафронов : К вопросу)
14:27:46	 From Alexander Dorofeyev : Спасибо большое!Всем хороших выходных!!!
14:28:04	 From Семён Шафронов : Спасибо большое!
14:28:06	 From Александр Бобр : Оч круто было спасибо! По поводу задерки - прошлая лекция из 3 часов затянулась на 6 часов)
14:28:51	 From Sergei : спасибо!
14:29:35	 From Victoria : спасибо, крайне понятно объясняете
14:30:27	 From Елена : Мы слушаем)
