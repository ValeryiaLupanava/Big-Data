11:00:14	 From Dmitry Vorob : Всю неделю молчал да?
11:00:58	 From Dmitry Vorob : Начинаем имхо
11:04:18	 From Михаил Новиков : c
11:04:18	 From Александр Бобр : D
11:04:19	 From Andrey : с
11:04:22	 From Dmitry Vorob : D
11:04:24	 From Максим Кобзев : С и D
11:04:26	 From Михаил Новиков : 0.375
11:04:43	 From Михаил Новиков :     #     [('A', 0.08333333333333333),
    #      ('D', 0.3333333333333333),
    #      ('B', 0.20833333333333331),
    #      ('C', 0.375)]
11:04:52	 From Максим Кобзев : =D
11:04:54	 From . : Или посмотрел
11:05:05	 From Михаил Новиков : в слаке писал
11:13:06	 From Михаил Новиков : вот теперь понял :)
11:14:29	 From Максим Кобзев : Что такое Cash?
11:14:44	 From Максим Кобзев : cache* =)
11:14:53	 From . : Big Sur  когда поставите?
11:14:56	 From Катерина Кучерявенко : а можно про flatMap пару слов? для каких случаев он применяется?
11:15:25	 From Михаил Новиков : когда используется бродкаст ?
11:16:36	 From Андрей Иванов : не разделяется слешом, если команды внутри скобок
11:17:00	 From Alexander Dorofeyev : Без \ драйвер не поймет, что это продолжение команды, в отличие от python
11:22:37	 From valeryialupanava : ,без сессии df не работает
11:23:08	 From Андрей Иванов : sc - rdd apisparksession - df api
11:32:14	 From Максим Кобзев : Неплохая подборка =)
11:32:18	 From . : Kinopoisk  - 1000 оценок, рекомендация так себе.
11:32:43	 From Ruslan Tskhovrebadze : Сосед пробудился ))
11:32:46	 From valeryialupanava : Может сосед тоже хорошие рекомендации хочет)
11:32:57	 From Андрей Иванов : требует даже)
11:33:04	 From Dmitry Vorob : Рекомендации о пункте назначения для этого соседа? )
11:34:04	 From allburn : Можно ли для dataframe делать show sample как мы делали для rdd?
11:35:23	 From valeryialupanava : withrenamedcolumn
11:35:41	 From Андрей Иванов : в show можно передать количество записей для отображения
11:36:12	 From allburn : Андрей, да, но я не это имею в виду : )
11:37:13	 From Alexander : Можно сделать df.sample(…).show()
11:41:52	 From Семён Шафронов : Т.е. MSSQL не совместим?
11:42:00	 From Dmitry Vorob : Head выбирает из произвольного файла, если файл распределен на хдфс?
11:42:23	 From . : А на Postgres и MySQL отдельные коннекторы или через JDBC?
11:44:00	 From valeryialupanava : .toDF
11:45:20	 From Александр Бобр : ДА!
11:49:12	 From Alexander : На постгрес точно чрезе jdbc есть
11:49:20	 From Alexander : На mysql тоже вроде
11:49:27	 From ysivan51 : Зачем вообще сначала читать файл в rdd, а потом в датафрейм, если возникают сложности с типами?
11:49:41	 From . : Мы просто к Oracle через JDBC подключаемся, хотелось бы узнать.
11:50:17	 From Alexander : Там везде есть jdbc, нужен только драйвер правильный
11:55:04	 From Andrey : почему репартишн делаем на 4, а не на 3? executor ов ведь 3
11:55:15	 From Семён Шафронов : +1
11:57:21	 From ysivan51 : Чтобы посмотреть количество партиций нужно обязательно превращать датафрейм в rdd? И насколько это сложная операция по времени?)
11:57:30	 From Семён Шафронов :  log.select(log.ip, log.code).show(5) - такой вариант показывает 1 датафрейм или 2 сериез объекта?
12:00:59	 From Alexander : Можно писать udf на скале, а все остальное на питоне, тогда будет норм
12:04:38	 From Alexander : Да scala то же самое, что питон, только val везде ставить надо)))
12:05:05	 From allburn : ))

12:09:06	 From Dmitry Vorob : По идее получается выгоднее кратно партиционировать
12:10:17	 From ysivan51 : а нельзя как-то зафиксировать каждому executor-у количество обрабатываемых партиций?
12:11:00	 From Михаил Новиков : они  живой очередью выбирают партиции, кто  закончил раньше, взял новую.. Это здорово :)
12:11:43	 From Dmitry Vorob : Да, поэтому партиций лучше чтоб было кратно
12:11:45	 From Dmitry Vorob : Мне кажется
12:14:04	 From Семён Шафронов : Интересно, что здесь в SQL запросе равнество - это ==, а не = как в обычном SQL
12:14:42	 From Андрей Иванов : партиции могут быть разного размера, да и воркеры могут работать с разной производительностью (железо в кластере может быть разное)в целом, хорошо бы иметь количество партиций не менее количества экзекьюторов, чтобы они не простаивали)
12:15:07	 From Alexander : Там в sql вроде обычное равенство = можно использовать
12:19:59	 From Андрей Иванов : flatmap
12:23:06	 From Valeryia : Наталья, поясни, пожалуйста, ещё раз, зачем в этом куске explode
12:24:03	 From Семён Шафронов : Если после explode выбирать из массива номер элемента по ключу, что будет, если в разных массивах разное кол-во элементов (напр., берем [10], а в одном массиве только 3 элемента)?
12:25:31	 From Valeryia : размножение строк будет
12:25:38	 From Valeryia : как в обычном джоине
12:25:50	 From Семён Шафронов : Спасибо
12:26:40	 From Dmitry Vorob : Во сколько продолжаем?
12:30:32	 From Oleg Agapov : В 12:35 продолжаем
12:40:48	 From Dmitry Vorob : А можно в пайчарме подключиться к нашему кластерному спарку и делать то же самое что и в жупитере?
12:57:56	 From Valeryia : nested loop
13:02:19	 From Семён Шафронов : Как влияет на join (скорость, оптимизация запросов) уникальность-не уникальность ключей?
13:02:27	 From Андрей Иванов : Наталья, а в каком случае ключи могут быть не сортируемы?
13:11:32	 From Dmitry Vorob : А как в проде вы вбираете как джойнить? на моменте разработки или же динамически высчитываете стратегию уже в моменте исполнения?
13:15:04	 From Dmitry Vorob : ну вобщем оптимизируется код под контректную инфраструктуру
13:31:47	 From Alexander : в пайспарк есть функция java_method
13:36:56	 From Михаил Новиков : уууу
13:41:40	 From Dmitry Vorob : 'builtin_function_or_method' object has no attribute 'pandas_udf'
13:41:45	 From Dmitry Vorob : че делать?
13:42:28	 From Станислав Картаев : import pyspark.sql.functions as f
13:42:41	 From Dmitry Vorob : дякую
13:45:32	 From Андрей Иванов : lf
13:45:33	 From Андрей Иванов : да
13:45:38	 From Dmitry Vorob : не, надо больше времени если совмем с нуля )
13:47:32	 From Андрей Иванов : log = spark.read.csv("/lectures/lecture02/data/logsM.txt", sep="\t", schema=log_schema).cache()from urllib.parse import urlparseimport pyspark.sql.functions as f@f.pandas_udf(StringType())def get_domain(x):    return(x.apply(lambda x: urlparse(x).netloc))log.withColumn('domain', get_domain('url')).select('url', 'domain').show()
13:47:47	 From Семён Шафронов : Спасибо!
13:48:07	 From Андрей Иванов : в слаке лучше отображается)
13:51:23	 From Андрей Иванов : в слаке в группе module-spark
13:51:29	 From Андрей Иванов : в другую надо?
13:51:46	 From Андрей Иванов : понял, сорри
13:53:40	 From Андрей Иванов : я же Андрей :(
13:56:17	 From Natalya Pritykovskaya : log = log.filter(log.domain == "news.mail.ru")

log = log.withColumn("timestamp", f.unix_timestamp(f.col("timestamp").cast("string"), "yyyyMMddHHmmss"))
13:58:24	 From Alexander : log.groupby("ip") \
    .agg(((f.max("timestamp") - f.min("timestamp"))/86400).alias("days")) \
    .orderBy(f.desc("days")) \
    .show(20)
14:00:09	 From Семён Шафронов : Спасибо! Взаимно.
14:00:09	 From Максим Кобзев : спасибо!
14:00:14	 From Андрей Иванов : спасибо!
14:00:15	 From Чеканов : спасибо!
14:00:15	 From sergey : Спасибо!
14:00:17	 From Ilia Komarov : Спасибо!
14:00:21	 From Tatiana : спасибо!
