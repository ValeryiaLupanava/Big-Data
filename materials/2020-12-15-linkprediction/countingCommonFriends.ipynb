{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"natasha pritykovskaya Link Prediction\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphPath = \"/lectures/lecture04/trainGraph\"\n",
    "usersToPredictPath = \"/lectures/lecture04/prediction.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema = StructType(fields=[\n",
    "    StructField(\"user\", IntegerType()),\n",
    "    StructField(\"friendsString\", StringType())\n",
    "])\n",
    "\n",
    "data = spark.read.format(\"csv\") \\\n",
    "        .schema(schema) \\\n",
    "        .option(\"delimiter\", \"\\t\") \\\n",
    "        .load(graphPath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|user|       friendsString|\n",
      "+----+--------------------+\n",
      "|1424|{(846,0),(1691,25...|\n",
      "|4128|{(49747,0),(53568...|\n",
      "|4480|{(4677,0),(22256,...|\n",
      "|4656|{(520,0),(12380,0...|\n",
      "|5040|{(629,0),(2471,0)...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, collect_list, sort_array, size, split, lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "def cutStartEndBrackets(series):\n",
    "    return series.str[2:-2]\n",
    "\n",
    "cutStartEndBracketsUDF = pandas_udf(cutStartEndBrackets, StringType())\n",
    "\n",
    "userFriend = \\\n",
    "    data.select(col(\"user\"), split(cutStartEndBracketsUDF(col(\"friendsString\")), \"\\),\\(\").alias(\"friendsMasks\"))\\\n",
    "    .withColumn(\"friendMask\", explode('friendsMasks'))\\\n",
    "    .withColumn(\"friend\", split(col(\"friendMask\"), \",\")[0])\\\n",
    "    .select(col(\"user\"), col(\"friend\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/step1.png\" width=700/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersWithCommonFriend = userFriend\\\n",
    "    .groupBy(\"friend\")\\\n",
    "    .agg(collect_list(\"user\").alias(\"usersWithCommonFriend\")) \\\n",
    "    .select(\"usersWithCommonFriend\")\\\n",
    "    .where(size(col(\"usersWithCommonFriend\")) >= 2)\\\n",
    "    .select(sort_array(\"usersWithCommonFriend\").alias(\"sortedUsersWithCommonFriend\"))\\\n",
    "    .drop(\"usersWithCommonFriend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/step2.png\" width=700/>\n",
    "<img src=\"pics/step3.png\" width=700/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|sortedUsersWithCommonFriend|\n",
      "+---------------------------+\n",
      "|          [131318, 2038934]|\n",
      "|       [11979968, 11979968]|\n",
      "|       [4471643, 4864911...|\n",
      "|           [39812, 3996243]|\n",
      "|       [34660, 960407, 1...|\n",
      "|         [215426, 10989590]|\n",
      "|       [294833, 3541819,...|\n",
      "|           [585940, 595464]|\n",
      "|         [7941296, 7941296]|\n",
      "|       [213875, 3310959,...|\n",
      "|       [1406846, 2044978...|\n",
      "|       [1208384, 1208384...|\n",
      "|        [2625623, 16545603]|\n",
      "|        [9787095, 11510201]|\n",
      "|       [1093525, 1543499...|\n",
      "|       [10599936, 10599936]|\n",
      "|       [5021715, 5262480...|\n",
      "|        [1651903, 10655397]|\n",
      "|       [1919, 582013, 35...|\n",
      "|         [3243642, 5845843]|\n",
      "+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usersWithCommonFriend.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_users_to_pred = StructType(fields=[\n",
    "    StructField(\"user\", IntegerType()),\n",
    "])\n",
    "\n",
    "usersToPredict = spark.read.format(\"csv\") \\\n",
    "    .schema(schema) \\\n",
    "    .load(usersToPredictPath) \\\n",
    "    .select(col(\"user\").cast(\"integer\")) \\\n",
    "    .rdd.map(lambda t : t.user).collect()\n",
    "\n",
    "usersToPredictBC = spark.sparkContext.broadcast(set(usersToPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType\n",
    "\n",
    "def pairsWithCommonFriend(usersWithCommonFriend):\n",
    "    pairs = []\n",
    "    for user1Index in range(0, len(usersWithCommonFriend)):\n",
    "        for user2Index in range(user1Index + 1, len(usersWithCommonFriend)):\n",
    "            if user1Index != user2Index:\n",
    "                if (usersWithCommonFriend[user1Index] in usersToPredictBC.value or \\\n",
    "                usersWithCommonFriend[user2Index] in usersToPredictBC.value):\n",
    "                    pairs.append((usersWithCommonFriend[user1Index], usersWithCommonFriend[user2Index]))\n",
    "    return pairs\n",
    "\n",
    "schema = ArrayType(ArrayType(IntegerType()))\n",
    "\n",
    "pairsWithCommonFriendUdf = udf(pairsWithCommonFriend, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/step4_2.png\" width=700/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|pairWithCommonFriend|count|\n",
      "+--------------------+-----+\n",
      "|   [340595, 2353061]|    2|\n",
      "|[12228454, 13773063]|   59|\n",
      "|   [608428, 2724603]|    2|\n",
      "|   [995605, 5126964]|    1|\n",
      "|   [971590, 9074160]|    2|\n",
      "|  [658247, 16584168]|  726|\n",
      "|[10610321, 12007797]|   16|\n",
      "|   [912457, 2514264]|    5|\n",
      "|  [850736, 14118378]|   48|\n",
      "| [1087903, 16519367]|    1|\n",
      "|  [1802940, 2995755]|    1|\n",
      "|  [2280725, 3192528]|   64|\n",
      "|  [3233402, 8128284]|   19|\n",
      "|  [461266, 11738162]|    2|\n",
      "|    [724636, 943158]|    1|\n",
      "|   [185916, 3792180]|    5|\n",
      "|   [434247, 3792180]|    1|\n",
      "|    [411957, 904004]|    6|\n",
      "|  [825709, 11243712]|  132|\n",
      "| [4626992, 10033766]|    6|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "import pandas as pd\n",
    "\n",
    "def pairsWithCommonFriend(series):\n",
    "    pairs_lists = []\n",
    "    for usersWithCommonFriend in series:\n",
    "        pairs = []\n",
    "        for user1Index in range(0, len(usersWithCommonFriend)):\n",
    "            for user2Index in range(user1Index + 1, len(usersWithCommonFriend)):\n",
    "                if user1Index != user2Index:\n",
    "                    if usersWithCommonFriend[user1Index] in usersToPredictBC.value or \\\n",
    "                    usersWithCommonFriend[user2Index] in usersToPredictBC.value:\n",
    "                        pairs.append((usersWithCommonFriend[user1Index], usersWithCommonFriend[user2Index]))\n",
    "        pairs_lists.append(pairs)\n",
    "    return pd.Series(pairs_lists)\n",
    "        \n",
    "pairsWithCommonFriendUdf = pandas_udf(pairsWithCommonFriend, schema)\n",
    "\n",
    "commonFriendsCounts = usersWithCommonFriend\\\n",
    "            .select(pairsWithCommonFriendUdf(\"sortedUsersWithCommonFriend\").alias(\"pairsWithCommonFriend\"))\\\n",
    "            .where(size(col(\"pairsWithCommonFriend\")) > 0)    \n",
    "\n",
    "commonFriendsCounts\\\n",
    "    .withColumn(\"pairWithCommonFriend\", explode(\"pairsWithCommonFriend\"))\\\n",
    "    .drop(col(\"pairsWithCommonFriend\"))\\\n",
    "    .groupBy(col(\"pairWithCommonFriend\"))\\\n",
    "    .count()\\\n",
    "    .show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairsWithCommonFriend(series):\n",
    "    pairs_lists = []\n",
    "    for usersWithCommonFriend in series:\n",
    "        pairs = []\n",
    "        for user1Index in range(0, len(usersWithCommonFriend)):\n",
    "            for user2Index in range(user1Index + 1, len(usersWithCommonFriend)):\n",
    "                if user1Index != user2Index:\n",
    "                    pairs.append((usersWithCommonFriend[user1Index], usersWithCommonFriend[user2Index]))\n",
    "        pairs_lists.append(pairs)\n",
    "    return pd.Series(pairs_lists)\n",
    "         \n",
    "pairsWithCommonFriendUdf = pandas_udf(pairsWithCommonFriend, schema)\n",
    "\n",
    "commonFriendsCounts = usersWithCommonFriend\\\n",
    "            .select(pairsWithCommonFriendUdf(\"sortedUsersWithCommonFriend\").alias(\"pairsWithCommonFriend\"))\\\n",
    "            .where(size(col(\"pairsWithCommonFriend\")) > 0)    \n",
    "\n",
    "commonFriendsCounts\\\n",
    "    .withColumn(\"pairWithCommonFriend\", explode(\"pairsWithCommonFriend\"))\\\n",
    "    .drop(col(\"pairsWithCommonFriend\"))\\\n",
    "    .groupBy(col(\"pairWithCommonFriend\"))\\\n",
    "    .count()\\\n",
    "    .show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def pairsWithCommonFriendUpgraded(series, modulo):\n",
    "    pairs_lists = []\n",
    "\n",
    "    for usersWithCommonFriend in series:\n",
    "        pairs = []\n",
    "        for user1Index in range(0, len(usersWithCommonFriend)):\n",
    "             for user2Index in range(user1Index + 1, len(usersWithCommonFriend)):\n",
    "                    if user1Index != user2Index and user1Index % 13 == modulo:\n",
    "                        pairs.append((usersWithCommonFriend[user1Index], usersWithCommonFriend[user2Index]))\n",
    "        pairs_lists.append(pairs)\n",
    "    return pd.Series(pairs_lists)\n",
    "\n",
    "\n",
    "for i in range(13):\n",
    "    pairsWithCommonFriendUdfUpgraded = pandas_udf(partial(pairsWithCommonFriendUpgraded, modulo=i), schema)\n",
    "\n",
    "    commonFriendsCounts = usersWithCommonFriend\\\n",
    "            .select(pairsWithCommonFriendUdfUpgraded(\"sortedUsersWithCommonFriend\").alias(\"pairsWithCommonFriend\"))\\\n",
    "            .where(size(col(\"pairsWithCommonFriend\")) > 0)\\\n",
    "            .write.parquet(\"pairs/\" + str(i), mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet(\"pairs/*\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet(\"pairs/0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|pairWithCommonFriend|count|\n",
      "+--------------------+-----+\n",
      "| [1481111, 15756137]|    1|\n",
      "| [8039479, 10812715]|    4|\n",
      "| [9102327, 16272182]|    1|\n",
      "|   [709520, 1563367]|    2|\n",
      "|    [200736, 228410]|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"pairs/*\")\\\n",
    "    .withColumn(\"pairWithCommonFriend\", explode(\"pairsWithCommonFriend\"))\\\n",
    "    .drop(col(\"pairsWithCommonFriend\"))\\\n",
    "    .groupBy(col(\"pairWithCommonFriend\"))\\\n",
    "    .count()\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
