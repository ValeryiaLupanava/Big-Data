{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import sql\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "from pyspark.mllib.feature import HashingTF, IDF\n",
    "from pyspark.mllib.feature import Normalizer\n",
    "\n",
    "import pyspark.sql.functions as psf\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "\n",
    "\n",
    "\n",
    "conf = SparkConf().setAppName(\"milkandbanana\").setMaster(\"local\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = sql.SQLContext(sc)\n",
    "\n",
    "#conf.set(\"spark.app.name\", \"milkandbanana Spark RDD app\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.history.kerberos.keytab', 'none'),\n",
       " ('spark.eventLog.enabled', 'true'),\n",
       " ('spark.history.ui.port', '18081'),\n",
       " ('spark.driver.extraLibraryPath',\n",
       "  '/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64'),\n",
       " ('spark.history.fs.cleaner.interval', '7d'),\n",
       " ('spark.shuffle.io.serverThreads', '128'),\n",
       " ('spark.sql.streaming.streamingQueryListeners', ''),\n",
       " ('spark.executor.extraLibraryPath',\n",
       "  '/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.shuffle.file.buffer', '1m'),\n",
       " ('spark.sql.hive.convertMetastoreOrc', 'true'),\n",
       " ('spark.yarn.dist.files', ''),\n",
       " ('spark.sql.autoBroadcastJoinThreshold', '26214400'),\n",
       " ('spark.jars',\n",
       "  'file:///data/home/viktorya.mukukenova/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.4.5.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/graphframes_graphframes-0.7.0-spark2.4-s_2.11.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/databricks_spark-sklearn-0.2.3.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.apache.kafka_kafka-clients-2.0.0.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.lz4_lz4-java-1.4.0.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.3.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'),\n",
       " ('spark.eventLog.dir', 'hdfs:///spark2-history/'),\n",
       " ('spark.files',\n",
       "  'file:///data/home/viktorya.mukukenova/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.4.5.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/graphframes_graphframes-0.7.0-spark2.4-s_2.11.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/databricks_spark-sklearn-0.2.3.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.apache.kafka_kafka-clients-2.0.0.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.lz4_lz4-java-1.4.0.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.3.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'),\n",
       " ('spark.sql.catalogImplementation', 'in-memory'),\n",
       " ('spark.executor.memory', '4g'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.sql.orc.impl', 'native'),\n",
       " ('spark.history.fs.logDirectory', 'hdfs:///spark2-history/'),\n",
       " ('spark.app.id', 'local-1605046157950'),\n",
       " ('spark.history.fs.cleaner.maxAge', '90d'),\n",
       " ('spark.extraListeners', ''),\n",
       " ('spark.driver.port', '42181'),\n",
       " ('spark.sql.warehouse.dir', '/apps/spark/warehouse'),\n",
       " ('spark.history.store.path', '/var/lib/spark2/shs_db'),\n",
       " ('spark.master', 'local'),\n",
       " ('spark.jars.packages',\n",
       "  'org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5,graphframes:graphframes:0.7.0-spark2.4-s_2.11,databricks:spark-sklearn:0.2.3'),\n",
       " ('spark.sql.execution.arrow.enabled', 'true'),\n",
       " ('spark.driver.memory', '4g'),\n",
       " ('spark.kryoserializer.buffer.max', '512m'),\n",
       " ('spark.sql.statistics.fallBackToHdfs', 'true'),\n",
       " ('spark.yarn.archive', 'hdfs:///tmp/spark-archive.zip'),\n",
       " ('spark.app.name', 'milkandbanana'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///data/home/viktorya.mukukenova/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.4.5.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/graphframes_graphframes-0.7.0-spark2.4-s_2.11.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/databricks_spark-sklearn-0.2.3.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.apache.kafka_kafka-clients-2.0.0.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.lz4_lz4-java-1.4.0.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.3.jar,file:///data/home/viktorya.mukukenova/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'),\n",
       " ('spark.history.provider',\n",
       "  'org.apache.spark.deploy.history.FsHistoryProvider'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/data/home/viktorya.mukukenova/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.11-2.4.5.jar,/data/home/viktorya.mukukenova/.ivy2/jars/graphframes_graphframes-0.7.0-spark2.4-s_2.11.jar,/data/home/viktorya.mukukenova/.ivy2/jars/databricks_spark-sklearn-0.2.3.jar,/data/home/viktorya.mukukenova/.ivy2/jars/org.apache.kafka_kafka-clients-2.0.0.jar,/data/home/viktorya.mukukenova/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar,/data/home/viktorya.mukukenova/.ivy2/jars/org.lz4_lz4-java-1.4.0.jar,/data/home/viktorya.mukukenova/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.3.jar,/data/home/viktorya.mukukenova/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.yarn.historyServer.address', 'bd-master.newprolab.com:18081'),\n",
       " ('spark.driver.host', 'bd-master.newprolab.com'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.extraClassPath', ''),\n",
       " ('spark.sql.hive.metastore.jars',\n",
       "  '/usr/hdp/current/spark2-client/standalone-metastore/*'),\n",
       " ('spark.driver.maxResultSize', '3900m'),\n",
       " ('spark.deploy-mode', 'client'),\n",
       " ('spark.yarn.queue', 'default'),\n",
       " ('spark.port.maxRetries', '50'),\n",
       " ('spark.history.fs.cleaner.enabled', 'true'),\n",
       " ('spark.sql.queryExecutionListeners', ''),\n",
       " ('spark.io.compression.lz4.blockSize', '128kb'),\n",
       " ('spark.executor.instances', '5'),\n",
       " ('spark.history.kerberos.principal', 'none'),\n",
       " ('spark.sql.orc.filterPushdown', 'true'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.shuffle.io.backLog', '8192'),\n",
       " ('spark.unsafe.sorter.spill.reader.buffer.size', '1m'),\n",
       " ('spark.executor.cores', '1'),\n",
       " ('spark.shuffle.unsafe.file.output.buffer', '5m'),\n",
       " ('spark.executor.extraJavaOptions', '-XX:+UseNUMA'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.sql.hive.metastore.version', '3.0')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   2 hdfs hdfs    1979173 2020-09-30 12:16 /labs/lab06data/ml-100k/u.data\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/lab06data/ml-100k/u.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   2 hdfs hdfs     236344 2020-09-30 12:16 /labs/lab06data/ml-100k/u.item\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/lab06data/ml-100k/u.item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_data = sc.textFile(\"/labs/lab06data/ml-100k/u.data\")\n",
    "rdd_item = sc.textFile(\"/labs/lab06data/ml-100k/u.item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['196\\t242\\t3\\t881250949',\n",
       " '186\\t302\\t3\\t891717742',\n",
       " '22\\t377\\t1\\t878887116',\n",
       " '244\\t51\\t2\\t880606923',\n",
       " '166\\t346\\t1\\t886397596',\n",
       " '298\\t474\\t4\\t884182806',\n",
       " '115\\t265\\t2\\t881171488',\n",
       " '253\\t465\\t5\\t891628467',\n",
       " '305\\t451\\t3\\t886324817',\n",
       " '6\\t86\\t3\\t883603013']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0',\n",
       " '2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0',\n",
       " '3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0',\n",
       " '4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0',\n",
       " '5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0',\n",
       " '6|Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)|01-Jan-1995||http://us.imdb.com/Title?Yao+a+yao+yao+dao+waipo+qiao+(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0',\n",
       " '7|Twelve Monkeys (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Twelve%20Monkeys%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|1|0|0|0',\n",
       " '8|Babe (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Babe%20(1995)|0|0|0|0|1|1|0|0|1|0|0|0|0|0|0|0|0|0|0',\n",
       " '9|Dead Man Walking (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Dead%20Man%20Walking%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0',\n",
       " '10|Richard III (1995)|22-Jan-1996||http://us.imdb.com/M/title-exact?Richard%20III%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|1|0']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_item.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      " |-- _3: string (nullable = true)\n",
      " |-- _4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = rdd_data.map(lambda x: x.split(\"\\t\"))\\\n",
    ".toDF()\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| _3|count|\n",
      "+---+-----+\n",
      "|  3|   69|\n",
      "|  5|   68|\n",
      "|  1|    8|\n",
      "|  4|  116|\n",
      "|  2|   19|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(data._2 == 234)\\\n",
    ".groupBy(\"_3\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| _3|count|\n",
      "+---+-----+\n",
      "|  3|27145|\n",
      "|  5|21201|\n",
      "|  1| 6110|\n",
      "|  4|34174|\n",
      "|  2|11370|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data\\\n",
    ".groupBy(\"_3\").count()\\\n",
    ".show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
