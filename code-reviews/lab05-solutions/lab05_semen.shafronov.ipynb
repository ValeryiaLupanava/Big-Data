{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# забираем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь к файлам\n",
    "path = '/data/share/lab05data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# текст для классификации\n",
    "id_text = [2561, 2049, 4, 2565, 2562, 2062, 3600, 3603, 3588, 534, 3607, 24, 25, 3612, 3102, 2591, 3804, 3627, 1580, 46, 1074, 2100, 3125, 56, 1593, 2485, 2621, 63, 3139, 2316, 610, 2121, 1098, 1099, 588, 2126, 2639, 88, 2140, 607, 1634, 2067, 612, 3175, 3178, 531, 1647, 1136, 1137, 1139, 1146, 1151, 22, 1710, 2692, 1160, 1674, 1560, 3729, 623, 3224, 153, 2206, 1183, 160, 3235, 3748, 684, 1651, 1711, 30, 1714, 2079, 695, 2232, 698, 189, 1227, 1025, 711, 3784, 2253, 2763, 3788, 1741, 2255, 1232, 3283, 383, 2775, 2265, 1829, 1244, 3300, 1767, 1257, 1320, 1747, 3830, 1152, 1279, 3030, 913, 3332, 1798, 2311, 386, 1289, 3340, 269, 1806, 274, 1425, 789, 2863, 1305, 2332, 800, 1825, 2339, 292, 293, 2855, 3368, 562, 2861, 3886, 2351, 2864, 307, 2356, 822, 1019, 3722, 2101, 3387, 2688, 829, 3904, 833, 2279, 3398, 2887, 336, 337, 3473, 854, 3420, 2398, 3426, 3939, 3940, 357, 2918, 1387, 2924, 879, 3442, 1396, 2421, 2427, 1407, 1345, 2438, 1928, 1419, 2456, 1054, 2030, 1937, 402, 2628, 2968, 409, 1437, 1956, 421, 1963, 943, 2481, 3509, 955, 2635, 2496, 455, 972, 3025, 1188, 3542, 3544, 3550, 482, 3699, 2812, 2534, 3566, 1521, 3570, 1525, 2043]\n",
    "test_texts = []\n",
    "for i in id_text:\n",
    "    f = open(path + 'test_' + str(i) +'.txt', \"r\")\n",
    "    test_texts.append(f.read())\n",
    "t_texts = pd.DataFrame(test_texts, columns = ['t_texts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# текст для обучения\n",
    "id_base_text = list(range(1, 21))\n",
    "base_texts = []\n",
    "for i in id_base_text:\n",
    "    f = open(path + 'base_' + str(i) +'.txt', \"r\")\n",
    "    base_texts.append(f.read())\n",
    "b_texts = pd.DataFrame(base_texts, columns = ['b_texts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#встроенные\n",
    "swords = stopwords.words(['english', 'russian'])\n",
    "#результат оценки статистики встречаемости. Добавлял интуитивно \"вручную\"\n",
    "swords = swords + ['знание', 'опыт', 'работы', 'strong', 'работа',\n",
    "'компания',\n",
    "'условие',\n",
    "'quot',\n",
    "'обязанность',\n",
    "'возможность',\n",
    "'работать',\n",
    "'заработный',\n",
    "'обучение',\n",
    "'профессиональный',\n",
    "'умение',\n",
    "'наш',\n",
    "'язык',\n",
    "'оформление',\n",
    "'офис',\n",
    "'рост',\n",
    "'график',\n",
    "'задача',\n",
    "'дать',\n",
    "'понимание',\n",
    "'навык',\n",
    "'карьерный',\n",
    "'уровень',\n",
    "'высокий',\n",
    "'решение',\n",
    "'клиент',\n",
    "'участие',\n",
    "'английский',\n",
    "'который',\n",
    "'коллектив',\n",
    "'принцип',\n",
    "'продукт',\n",
    "'хороший',\n",
    "'официальный',\n",
    "'контроль',\n",
    "'свой',\n",
    "'интересный',\n",
    "'использование',\n",
    "'развитие',\n",
    "'рабочий',\n",
    "'результат']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# создаем вектор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#из лекции функция\n",
    "GROUPING_SPACE_REGEX = re.compile(r'([^\\w]|[+])', re.UNICODE)\n",
    "def simple_word_tokenize(text, _split=GROUPING_SPACE_REGEX.split):\n",
    "    return [t for t in _split(text.lower()) if t and not t.isspace()]\n",
    "m = pymorphy2.MorphAnalyzer()\n",
    "def token_r(text):\n",
    "    words = simple_word_tokenize(text)\n",
    "    return [m.parse(x)[0].normal_form for x in words if len(x) > 3]\n",
    "\n",
    "cv = CountVectorizer(stop_words = swords, tokenizer=token_r)\n",
    "\n",
    "css = cv.fit_transform(b_texts.b_texts).toarray()\n",
    "css2 = cv.transform(t_texts.t_texts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# встречаемость слов для пополнения словаря стоп-слов\n",
    "words = [y[0] for y in sorted(cv.vocabulary_.items(), key=lambda x: x[1])]\n",
    "c_words = zip(words, sum(css2))\n",
    "c_words = sorted(c_words, key=lambda x: x[1], reverse=True)\n",
    "c_words[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# считаем косинусную близость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#суммируем косинусные близости каждого текста из стестовой и 20 обучающих текстов\n",
    "ilo = []\n",
    "\n",
    "for j in range(len(css2)):\n",
    "    lkl = 0\n",
    "    for i in range(len(css)):\n",
    "        lkl += cosine_similarity(css[i].reshape(1, -1), css2[j].reshape(1, -1))[0][0]\n",
    "    ilo.append(lkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# порог решения, если выше, то тип определен\n",
    "thrshld = np.mean(ilo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# трансформируем результат в датафрейм (просто, лично мне так удобнее обрабатывать)\n",
    "df_ilo = pd.DataFrame(ilo, columns = ['ilo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем с исходными текстами, чтобы достать индексы\n",
    "end_calc = pd.concat([t_texts, df_ilo], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_texts</th>\n",
       "      <th>ilo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;Мы ищем талантливых и целеустремленных спец...</td>\n",
       "      <td>4.117645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Чем придется заниматься:&lt;/strong&gt;&lt;/...</td>\n",
       "      <td>3.646620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>4.569716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;Ищем опытных разработчиков под Android для ...</td>\n",
       "      <td>3.900656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;&lt;em&gt;Работа в Германии&lt;/em&gt;&lt;/strong&gt;...</td>\n",
       "      <td>1.392930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             t_texts       ilo\n",
       "0  <p>Мы ищем талантливых и целеустремленных спец...  4.117645\n",
       "1  <p><strong>Чем придется заниматься:</strong></...  3.646620\n",
       "2  <p><strong>Обязанности</strong>:</p> <ul> <li>...  4.569716\n",
       "3  <p>Ищем опытных разработчиков под Android для ...  3.900656\n",
       "4  <p><strong><em>Работа в Германии</em></strong>...  1.392930"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_calc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделяем на определенные и не определенные.\n",
    "\n",
    "dict_to_out = {}\n",
    "defd = []\n",
    "othr = []\n",
    "\n",
    "for i in range(len(end_calc)):\n",
    "    to_ins = id_text[i] #преобразовываем в инт, т.к. json не понимает numpy\n",
    "    if end_calc.ilo[i] >= thrshld:\n",
    "        defd.append(to_ins)\n",
    "    else:\n",
    "        othr.append(to_ins)\n",
    "    \n",
    "dict_to_out = {\n",
    "    'defined' : sorted(defd),\n",
    "    'other' : sorted(othr)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводим в файл\n",
    "import json\n",
    "\n",
    "with open('lab05.json', 'w') as outfile:\n",
    "    json.dump(dict_to_out, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
