{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pymorphy2\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_texts = [2561, 4, 5, 1111, 522, 3084, 3090, 3343, 2968, 534, 2583, 536, 2565, 2588, 2591, 2084, 2603, 1580, 2606, \n",
    "             1072, 1074, 52, 2101, 572, 2622, 63, 2624, 3649, 1602, 587, 588, 78, 1294, 3154, 2134, 599, 89, 1115, \n",
    "             1632, 2148, 1125, 2066, 701, 2668, 2067, 3183, 3184, 1137, 2167, 1658, 3708, 1152, 3713, 2692, 133, \n",
    "             2184, 3214, 3730, 196, 3927, 3222, 538, 2201, 668, 2206, 161, 680, 1200, 176, 177, 2228, 1717, 2744, \n",
    "             3468, 2238, 3775, 3264, 1218, 3268, 710, 3783, 712, 1740, 2224, 1747, 548, 3285, 724, 2682, 3804, 1404, \n",
    "             2855, 3925, 1806, 2259, 1779, 3180, 3317, 3318, 1273, 213, 1323, 1281, 812, 1798, 1289, 3850, 2316, \n",
    "             3854, 783, 3886, 2323, 3352, 1669, 3357, 1825, 290, 1827, 2343, 1320, 299, 2696, 301, 814, 2353, \n",
    "             2357, 822, 311, 1343, 832, 1345, 2370, 1347, 1348, 2374, 2379, 1166, 3300, 2389, 854, 3415, 859, \n",
    "             352, 3939, 658, 2144, 879, 880, 1394, 1396, 1911, 377, 2427, 3904, 1406, 384, 897, 903, 1928, 908, \n",
    "             1423, 3472, 3473, 1689, 1860, 917, 2456, 3481, 2973, 414, 2467, 421, 1961, 429, 3827, 2480, 945, 441, \n",
    "             3829, 1469, 758, 3013, 3526, 3025, 2003, 468, 3030, 1344, 1500, 2526, 3551, 2535, 3562, 665, 3564, \n",
    "             1519, 2901, 2200, 510, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p>В Группе компаний InfoWatch, которая объединяет ряд российских и зарубежных разработчиков программных продуктов и решений для обеспечения информационной безопасности организаций, противодействия внешним и внутренним угрозам, на конкурсной основе, открыта вакансия <strong>Старший программист C++ (лингвистические технологии).</strong></p> <p><strong>Обязанности:</strong></p> <ul> </ul> <ul> <li>разработка алгоритмов и их реализация на C++;</li> <li>составление технической документации по разрабатываемым компонентам;</li> <li>разработка unit-тестов;</li> <li>разработка, отладка, модификация и оптимизация отдельных сложных компонентов программной системы в соответствии с заданиями, выданными непосредственным руководителем;</li> <li>обзоры кода других разработчиков и рекомендации по его улучшению.</li> </ul> <p> </p> <p><strong>Требования:</strong></p> <ul> <li>знание <strong>С++ </strong>(опыт программирования от 3 лет);</li> <li>знания алгоритмов и структуры данных;</li> <li>высокая культура программирования;</li> <li>опыт работы в команде, умение быстро разбираться в чужом коде;</li> </ul> <p><strong><em>Желательно:</em></strong></p> <ul> <li>опыт программирования под Linux;</li> <li>желателен опыт в обработке текстовой информации и разработке алгоритмов машинного обучения;</li> <li>желательно наличие математического образования, умения статистически обрабатывать данные, хорошая общая алгоритмическая подготовка;</li> <li>обработка изображений и компьютерное зрение.</li> </ul> <p><strong>Условия</strong>:</p> <ul> <li>конкурентоспособная оплата труда;</li> <li>полное соблюдение ТК РФ;</li> <li>работа в сплоченной команде единомышленников;</li> <li>самореализация;</li> <li>ориентация на результат;</li> <li>забота о здоровье: мини-спортзал в офисе, оплачиваемое питание, возможность оформления льготного ДМС, велопарковка;</li> <li>уютный офис: зоны отдыха с настольным теннисом, аэрохоккеем и видеоиграми, чай-кофе-плюшки-печеньки в течение дня, снековые автоматы;</li> <li>интересные события и активный отдых: регулярные фотовыставки, творческие конкурсы для сотрудников и их детей, корпоративные мероприятия;</li> <li> <p>и многое другое...</p> </li> </ul> <p><strong>ЖДЕМ ВАС В НАШЕЙ КОМАНДЕ!</strong></p>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from file.\n",
    "with open('/data/share/lab05data/base_19.txt') as f:\n",
    "    book = f.readlines()\n",
    "book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# The * is not a regex, it just means \"match anything\"\n",
    "# This matches datafile-0.csv, datafile-1.csv, etc.\n",
    "list_base = glob.glob('/data/share/lab05data/base_*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/share/lab05data/base_19.txt',\n",
       " '/data/share/lab05data/base_3.txt',\n",
       " '/data/share/lab05data/base_13.txt',\n",
       " '/data/share/lab05data/base_8.txt',\n",
       " '/data/share/lab05data/base_1.txt',\n",
       " '/data/share/lab05data/base_14.txt',\n",
       " '/data/share/lab05data/base_6.txt',\n",
       " '/data/share/lab05data/base_12.txt',\n",
       " '/data/share/lab05data/base_17.txt',\n",
       " '/data/share/lab05data/base_7.txt',\n",
       " '/data/share/lab05data/base_10.txt',\n",
       " '/data/share/lab05data/base_2.txt',\n",
       " '/data/share/lab05data/base_4.txt',\n",
       " '/data/share/lab05data/base_15.txt',\n",
       " '/data/share/lab05data/base_9.txt',\n",
       " '/data/share/lab05data/base_18.txt',\n",
       " '/data/share/lab05data/base_16.txt',\n",
       " '/data/share/lab05data/base_20.txt',\n",
       " '/data/share/lab05data/base_11.txt',\n",
       " '/data/share/lab05data/base_5.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('/data/share/lab05data/base_*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Turn those into a list of dataframes\n",
    "# df_list_base = [pd.read_csv(filename) for filename in list_base]\n",
    "# # df_list_base[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataframe, filename in zip(df_list_base, list_base):\n",
    "#   dataframe['filename'] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df = pd.concat(df_list_base, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_and_text = {}\n",
    "for file in list_base:\n",
    "    with open (file, \"r\") as basefile:\n",
    "        file_name_and_text[file] = basefile.read()\n",
    "df_list_base = (pd.DataFrame.from_dict(file_name_and_text, orient='index').reset_index().rename(index = str, columns = {'index': 'file_name', 0: 'text'}))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (file_name_and_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_base\n",
    "# df_list_base['id_base'] = df_list_base['file_name'].str.extract('(\\d+)').astype(int)\n",
    "# df_list_base['id_base_1'] = df_list_base['file_name'].str.split('lab05data')[-1].str.extract('(\\d+)').astype(int)\n",
    "# df_list_base\n",
    "df_list_base['id_base'] = df_list_base['file_name'].str.findall(r'[^a-z/.]+').apply(''.join).str.split('_').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>id_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/share/lab05data/base_19.txt</td>\n",
       "      <td>&lt;p&gt;В Группе компаний InfoWatch, которая объеди...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/share/lab05data/base_3.txt</td>\n",
       "      <td>&lt;p&gt;NetCracker Technology Corp., a large softwa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/share/lab05data/base_13.txt</td>\n",
       "      <td>&lt;p&gt; &lt;/p&gt; &lt;p&gt;Компания Wargaming приглашает в св...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/share/lab05data/base_8.txt</td>\n",
       "      <td>&lt;p&gt;Компания Wargaming в лице команды-разработч...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/share/lab05data/base_1.txt</td>\n",
       "      <td>&lt;p&gt;Ищем прекрасного программиста 1С в дружный ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/data/share/lab05data/base_14.txt</td>\n",
       "      <td>&lt;p&gt;Разработчик нашей мечты (java developer)&lt;/p...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/data/share/lab05data/base_6.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;NetCracker Technology&lt;/strong&gt;&lt;/p&gt; ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/data/share/lab05data/base_12.txt</td>\n",
       "      <td>&lt;p&gt; &lt;/p&gt; &lt;p&gt;Компания Wargaming приглашает в св...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/data/share/lab05data/base_17.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Группа компаний InfoWatch&lt;/strong&gt;,...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/data/share/lab05data/base_7.txt</td>\n",
       "      <td>&lt;p&gt;NetCracker Technology Corp., a large softwa...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/data/share/lab05data/base_10.txt</td>\n",
       "      <td>&lt;p&gt;Компания Wargaming в лице команды-разработч...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/data/share/lab05data/base_2.txt</td>\n",
       "      <td>&lt;p&gt;Предлагаем уникальную возможность присоедин...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/data/share/lab05data/base_4.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Senior Java software engineer в Отд...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/data/share/lab05data/base_15.txt</td>\n",
       "      <td>Крупная инвестиционная компания ищет в свою ко...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/data/share/lab05data/base_9.txt</td>\n",
       "      <td>&lt;p&gt;Компания Wargaming в лице команды-разработч...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>/data/share/lab05data/base_18.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Группа компаний InfoWatch&lt;/strong&gt;,...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>/data/share/lab05data/base_16.txt</td>\n",
       "      <td>&lt;p&gt;ИТ-компания ищет в свою команду талантливог...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/data/share/lab05data/base_20.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Группа компаний InfoWatch&lt;/strong&gt;,...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/data/share/lab05data/base_11.txt</td>\n",
       "      <td>&lt;p&gt;JavaScript Developer (Worldoftanks.ru)&lt;/p&gt; ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/data/share/lab05data/base_5.txt</td>\n",
       "      <td>&lt;p&gt;NetCracker Technology Corp., a large softwa...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            file_name  \\\n",
       "0   /data/share/lab05data/base_19.txt   \n",
       "1    /data/share/lab05data/base_3.txt   \n",
       "2   /data/share/lab05data/base_13.txt   \n",
       "3    /data/share/lab05data/base_8.txt   \n",
       "4    /data/share/lab05data/base_1.txt   \n",
       "5   /data/share/lab05data/base_14.txt   \n",
       "6    /data/share/lab05data/base_6.txt   \n",
       "7   /data/share/lab05data/base_12.txt   \n",
       "8   /data/share/lab05data/base_17.txt   \n",
       "9    /data/share/lab05data/base_7.txt   \n",
       "10  /data/share/lab05data/base_10.txt   \n",
       "11   /data/share/lab05data/base_2.txt   \n",
       "12   /data/share/lab05data/base_4.txt   \n",
       "13  /data/share/lab05data/base_15.txt   \n",
       "14   /data/share/lab05data/base_9.txt   \n",
       "15  /data/share/lab05data/base_18.txt   \n",
       "16  /data/share/lab05data/base_16.txt   \n",
       "17  /data/share/lab05data/base_20.txt   \n",
       "18  /data/share/lab05data/base_11.txt   \n",
       "19   /data/share/lab05data/base_5.txt   \n",
       "\n",
       "                                                 text id_base  \n",
       "0   <p>В Группе компаний InfoWatch, которая объеди...      19  \n",
       "1   <p>NetCracker Technology Corp., a large softwa...       3  \n",
       "2   <p> </p> <p>Компания Wargaming приглашает в св...      13  \n",
       "3   <p>Компания Wargaming в лице команды-разработч...       8  \n",
       "4   <p>Ищем прекрасного программиста 1С в дружный ...       1  \n",
       "5   <p>Разработчик нашей мечты (java developer)</p...      14  \n",
       "6   <p><strong>NetCracker Technology</strong></p> ...       6  \n",
       "7   <p> </p> <p>Компания Wargaming приглашает в св...      12  \n",
       "8   <p><strong>Группа компаний InfoWatch</strong>,...      17  \n",
       "9   <p>NetCracker Technology Corp., a large softwa...       7  \n",
       "10  <p>Компания Wargaming в лице команды-разработч...      10  \n",
       "11  <p>Предлагаем уникальную возможность присоедин...       2  \n",
       "12  <p><strong>Senior Java software engineer в Отд...       4  \n",
       "13  Крупная инвестиционная компания ищет в свою ко...      15  \n",
       "14  <p>Компания Wargaming в лице команды-разработч...       9  \n",
       "15  <p><strong>Группа компаний InfoWatch</strong>,...      18  \n",
       "16  <p>ИТ-компания ищет в свою команду талантливог...      16  \n",
       "17  <p><strong>Группа компаний InfoWatch</strong>,...      20  \n",
       "18  <p>JavaScript Developer (Worldoftanks.ru)</p> ...      11  \n",
       "19  <p>NetCracker Technology Corp., a large softwa...       5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_base</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>/data/share/lab05data/base_19.txt</td>\n",
       "      <td>&lt;p&gt;В Группе компаний InfoWatch, которая объеди...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/share/lab05data/base_3.txt</td>\n",
       "      <td>&lt;p&gt;NetCracker Technology Corp., a large softwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/data/share/lab05data/base_13.txt</td>\n",
       "      <td>&lt;p&gt; &lt;/p&gt; &lt;p&gt;Компания Wargaming приглашает в св...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/data/share/lab05data/base_8.txt</td>\n",
       "      <td>&lt;p&gt;Компания Wargaming в лице команды-разработч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/share/lab05data/base_1.txt</td>\n",
       "      <td>&lt;p&gt;Ищем прекрасного программиста 1С в дружный ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name  \\\n",
       "id_base                                      \n",
       "19       /data/share/lab05data/base_19.txt   \n",
       "3         /data/share/lab05data/base_3.txt   \n",
       "13       /data/share/lab05data/base_13.txt   \n",
       "8         /data/share/lab05data/base_8.txt   \n",
       "1         /data/share/lab05data/base_1.txt   \n",
       "\n",
       "                                                      text  \n",
       "id_base                                                     \n",
       "19       <p>В Группе компаний InfoWatch, которая объеди...  \n",
       "3        <p>NetCracker Technology Corp., a large softwa...  \n",
       "13       <p> </p> <p>Компания Wargaming приглашает в св...  \n",
       "8        <p>Компания Wargaming в лице команды-разработч...  \n",
       "1        <p>Ищем прекрасного программиста 1С в дружный ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list_base.set_index('id_base',inplace=True)\n",
    "df_list_base.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/share/lab05data/test_2561.txt',\n",
       " '/data/share/lab05data/test_4.txt',\n",
       " '/data/share/lab05data/test_5.txt',\n",
       " '/data/share/lab05data/test_1111.txt',\n",
       " '/data/share/lab05data/test_522.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_test = []\n",
    "for i in id_texts:\n",
    "    list_test.append(f'/data/share/lab05data/test_{i}.txt')\n",
    "list_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_and_text_test = {}\n",
    "for file in list_test:\n",
    "    with open (file, \"r\") as testfile:\n",
    "        file_name_and_text_test[file] = testfile.read()\n",
    "df_list_test = (pd.DataFrame.from_dict(file_name_and_text_test, orient='index').reset_index()\n",
    "                .rename(index = str, columns = {'index': 'file_name', 0: 'text'}))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>id_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/share/lab05data/test_2561.txt</td>\n",
       "      <td>&lt;p&gt;Мы ищем талантливых и целеустремленных спец...</td>\n",
       "      <td>2561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/share/lab05data/test_4.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/share/lab05data/test_5.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/share/lab05data/test_1111.txt</td>\n",
       "      <td>&lt;p&gt;В сеть салонов Ваша Оптика требуется продав...</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/share/lab05data/test_522.txt</td>\n",
       "      <td>&lt;p&gt;Компания приглашает специалиста для разовой...</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_name  \\\n",
       "0  /data/share/lab05data/test_2561.txt   \n",
       "1     /data/share/lab05data/test_4.txt   \n",
       "2     /data/share/lab05data/test_5.txt   \n",
       "3  /data/share/lab05data/test_1111.txt   \n",
       "4   /data/share/lab05data/test_522.txt   \n",
       "\n",
       "                                                text id_test  \n",
       "0  <p>Мы ищем талантливых и целеустремленных спец...    2561  \n",
       "1  <p><strong>Обязанности</strong>:</p> <ul> <li>...       4  \n",
       "2  <p><strong>Обязанности:</strong></p> <ul> <li>...       5  \n",
       "3  <p>В сеть салонов Ваша Оптика требуется продав...    1111  \n",
       "4  <p>Компания приглашает специалиста для разовой...     522  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list_test['id_test'] = df_list_test['file_name'].str.findall(r'[^a-z/.]+').apply(''.join).str.split('_').str[1]\n",
    "df_list_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>/data/share/lab05data/test_2561.txt</td>\n",
       "      <td>&lt;p&gt;Мы ищем талантливых и целеустремленных спец...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/share/lab05data/test_4.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/data/share/lab05data/test_5.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>/data/share/lab05data/test_1111.txt</td>\n",
       "      <td>&lt;p&gt;В сеть салонов Ваша Оптика требуется продав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>/data/share/lab05data/test_522.txt</td>\n",
       "      <td>&lt;p&gt;Компания приглашает специалиста для разовой...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file_name  \\\n",
       "id_test                                        \n",
       "2561     /data/share/lab05data/test_2561.txt   \n",
       "4           /data/share/lab05data/test_4.txt   \n",
       "5           /data/share/lab05data/test_5.txt   \n",
       "1111     /data/share/lab05data/test_1111.txt   \n",
       "522       /data/share/lab05data/test_522.txt   \n",
       "\n",
       "                                                      text  \n",
       "id_test                                                     \n",
       "2561     <p>Мы ищем талантливых и целеустремленных спец...  \n",
       "4        <p><strong>Обязанности</strong>:</p> <ul> <li>...  \n",
       "5        <p><strong>Обязанности:</strong></p> <ul> <li>...  \n",
       "1111     <p>В сеть салонов Ваша Оптика требуется продав...  \n",
       "522      <p>Компания приглашает специалиста для разовой...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list_test.set_index('id_test',inplace=True)\n",
    "df_list_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>/data/share/lab05data/test_2561.txt</td>\n",
       "      <td>&lt;p&gt;Мы ищем талантливых и целеустремленных спец...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/share/lab05data/test_4.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/data/share/lab05data/test_5.txt</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>/data/share/lab05data/test_1111.txt</td>\n",
       "      <td>&lt;p&gt;В сеть салонов Ваша Оптика требуется продав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>/data/share/lab05data/test_522.txt</td>\n",
       "      <td>&lt;p&gt;Компания приглашает специалиста для разовой...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file_name  \\\n",
       "id_test                                        \n",
       "2561     /data/share/lab05data/test_2561.txt   \n",
       "4           /data/share/lab05data/test_4.txt   \n",
       "5           /data/share/lab05data/test_5.txt   \n",
       "1111     /data/share/lab05data/test_1111.txt   \n",
       "522       /data/share/lab05data/test_522.txt   \n",
       "\n",
       "                                                      text  \n",
       "id_test                                                     \n",
       "2561     <p>Мы ищем талантливых и целеустремленных спец...  \n",
       "4        <p><strong>Обязанности</strong>:</p> <ul> <li>...  \n",
       "5        <p><strong>Обязанности:</strong></p> <ul> <li>...  \n",
       "1111     <p>В сеть салонов Ваша Оптика требуется продав...  \n",
       "522      <p>Компания приглашает специалиста для разовой...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /data/home/ekaterina.kucheryavenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /data/home/ekaterina.kucheryavenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# работа со стоп-словам\n",
    "from nltk.corpus import stopwords\n",
    "stop_en = set(stopwords.words('english'))\n",
    "stop_ru = set(stopwords.words('russian'))\n",
    "stop_words = set(['p','li','ul','url', 'компания', 'стать', 'зарплата', 'зарп'])\n",
    "stop_words.update(stop_en,stop_ru)\n",
    "def stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in stop_words and len(word)>2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_en)\n",
    "len(stop_ru)\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Мы ищем талантливых и целеустремленных специалистов для работы в Санкт-Петербургском центре разработок.</p> <p><strong>Вам предстоит:</strong></p> <ul> <li>Разрабатывать и сопровождать систему автоматической установки и конфигурирования программных сред.</li> <li>Проектировать архитектуру, выбирать программные средства.</li> <li>Работать с отделами разработки, тестирования и администрирования: сбор требований, расширение функционала системы, выпуск новых версий.</li> </ul> <p> </p> <p><strong>Наши ожидания:</strong></p> <ul> <li>Опыт разработки программного обеспечения от 5-ти лет.</li> <li>Опыт разработки back-end систем на Python.</li> <li>Опыт разработки web-интерфейсов с использованием HTML, JS, CSS, Python, Django.</li> <li>Опыт работы с СУБД: PostgreSQL.</li> <li>Владение объектно-ориентированной методологией, шаблонами проектирования (OOD Patterns).</li> <li>Опыт разработки High Availability систем.</li> <li>English - intermediate.</li> </ul> <p> </p> <p><strong>Мы предлагаем:</strong></p> <ul> <li>Индексируемую заработную плату.</li> <li>100% оплату больничного.</li> <li>Отпуск 28 календарных дней, оплачиваемый 100% в соответствии с текущей ставкой.</li> <li>Медицинское сопровождение (ДМС, офисный врач, стоматология).</li> <li>Корпоративные обучающие программы, курсы английского языка.</li> <li>Широкие возможности для самореализации, профессионального и карьерного роста.</li> <li>Возможность командировок и дальнейшей работы в зарубежных представительствах компании (в т.ч. H1-B США, Филиппины, Китай).</li> <li>Комфортные условия работы, современный бизнес-центр, удобные кресла, велопарковку, оборудованные кухни, чай, кофе, прохладительные напитки и сладости.</li> <li>Корпоративные праздники, выезды, спорт.</li> <li>Офис в 10-ти минутах ходьбы от метро.</li> <li>Иногородним кандидатам предоставляется Relocation Bonus и помощь в поиске жилья в Санкт-Петербурге.</li> </ul>\n",
      "Мы ищем талантливых и целеустремленных специалистов для работы в Санкт-Петербургском центре разработок. Вам предстоит:  Разрабатывать и сопровождать систему автоматической установки и конфигурирования программных сред. Проектировать архитектуру, выбирать программные средства. Работать с отделами разработки, тестирования и администрирования: сбор требований, расширение функционала системы, выпуск новых версий.    Наши ожидания:  Опыт разработки программного обеспечения от 5-ти лет. Опыт разработки back-end систем на Python. Опыт разработки web-интерфейсов с использованием HTML, JS, CSS, Python, Django. Опыт работы с СУБД: PostgreSQL. Владение объектно-ориентированной методологией, шаблонами проектирования (OOD Patterns). Опыт разработки High Availability систем. English - intermediate.    Мы предлагаем:  Индексируемую заработную плату. 100% оплату больничного. Отпуск 28 календарных дней, оплачиваемый 100% в соответствии с текущей ставкой. Медицинское сопровождение (ДМС, офисный врач, стоматология). Корпоративные обучающие программы, курсы английского языка. Широкие возможности для самореализации, профессионального и карьерного роста. Возможность командировок и дальнейшей работы в зарубежных представительствах компании (в т.ч. H1-B США, Филиппины, Китай). Комфортные условия работы, современный бизнес-центр, удобные кресла, велопарковку, оборудованные кухни, чай, кофе, прохладительные напитки и сладости. Корпоративные праздники, выезды, спорт. Офис в 10-ти минутах ходьбы от метро. Иногородним кандидатам предоставляется Relocation Bonus и помощь в поиске жилья в Санкт-Петербурге. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/bd9/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda/envs/bd9/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup into your workspace\n",
    "from bs4 import BeautifulSoup             \n",
    "\n",
    "# Initialize the BeautifulSoup object on a single movie review     \n",
    "example1 = BeautifulSoup(df_list_test.text[0])  \n",
    "\n",
    "# Print the raw review and then the output of get_text(), for \n",
    "# comparison\n",
    "print (df_list_test.text[0])\n",
    "print (example1.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы ищем талантливых и целеустремленных специалистов для работы в Санкт Петербургском центре разработок  Вам предстоит   Разрабатывать и сопровождать систему автоматической установки и конфигурирования программных сред  Проектировать архитектуру  выбирать программные средства  Работать с отделами разработки  тестирования и администрирования  сбор требований  расширение функционала системы  выпуск новых версий     Наши ожидания   Опыт разработки программного обеспечения от   ти лет  Опыт разработки back end систем на Python  Опыт разработки web интерфейсов с использованием HTML  JS  CSS  Python  Django  Опыт работы с СУБД  PostgreSQL  Владение объектно ориентированной методологией  шаблонами проектирования  OOD Patterns   Опыт разработки High Availability систем  English   intermediate     Мы предлагаем   Индексируемую заработную плату       оплату больничного  Отпуск    календарных дней  оплачиваемый      в соответствии с текущей ставкой  Медицинское сопровождение  ДМС  офисный врач  стоматология   Корпоративные обучающие программы  курсы английского языка  Широкие возможности для самореализации  профессионального и карьерного роста  Возможность командировок и дальнейшей работы в зарубежных представительствах компании  в т ч  H  B США  Филиппины  Китай   Комфортные условия работы  современный бизнес центр  удобные кресла  велопарковку  оборудованные кухни  чай  кофе  прохладительные напитки и сладости  Корпоративные праздники  выезды  спорт  Офис в    ти минутах ходьбы от метро  Иногородним кандидатам предоставляется Relocation Bonus и помощь в поиске жилья в Санкт Петербурге  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Use regular expressions to do a find-and-replace\n",
    "letters_only = re.sub(\"[^a-zA-Zа-яА-Я]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      example1.get_text() )  # The text to search\n",
    "print (letters_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = BeautifulSoup(text)\n",
    "    text = text.get_text()\n",
    "    text = re.sub(\"[^a-zA-Zа-яА-Я]\", \" \", text) \n",
    "    # Tokenise words while ignoring punctuation\n",
    "    text = re.sub('\\-\\s\\r\\n\\s{1,}|\\-\\s\\r\\n|\\r\\n', '', text) #deleting newlines and line-breaks\n",
    "    text = re.sub('[.,:;%©?*,!@#$%^&()\\d]|[+=]|[[]|[]]|[/]|\"|\\s{2,}|-', ' ', text) #deleting symbols\n",
    "    \n",
    "    tokeniser = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokeniser.tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    keywords= [token for token in tokens if token not in stop_words and len(token)>3]\n",
    "    \n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    lemmas = [morph.parse(keyword)[0].normal_form for keyword in keywords]\n",
    "    \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    words = [lemmatiser.lemmatize(token) for token in lemmas]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# import re\n",
    "# GROUPING_SPACE_REGEX = re.compile(r'([^\\w]|[+])', re.UNICODE)\n",
    "# def simple_word_tokenize(text, _split=GROUPING_SPACE_REGEX.split):\n",
    "#     return [t for t in _split(text.lower()) if t and not t.isspace()]\n",
    "\n",
    "# def token_r(text):\n",
    "#     words = simple_word_tokenize(text)\n",
    "#     return [m.parse(x)[0].normal_form for x in words if len(x) >= 4]\n",
    "\n",
    "# import pymorphy2\n",
    "# m = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = preprocess_text(df_list_base.text[1])\n",
    "# type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b8a8aaa855409fa93453304bea6662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "test_set = [preprocess_text(txt) for txt in tqdm(df_list_test.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_list_test.text[0]\n",
    "# test_set = [preprocess_text(txt) for txt in tqdm(df_list_test.text[0])]\n",
    "test_set = preprocess_text(df_1)\n",
    "# test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # создание словаря из уникальных слов\n",
    "# wrd_index = gensim.corpora.Dictionary(bow_txts)\n",
    "# print(wrd_index .token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_above = 0.5\n",
    "# buzzwords = {}\n",
    "# for key, val in wrd_index.items():\n",
    "#   if wrd_index.dfs[key] > no_above * wrd_index.num_docs:\n",
    "#     buzzwords[val] = wrd_index.dfs[key]/wrd_index.num_docs\n",
    "# wrd_index.filter_extremes(no_above=no_above, no_below=4, keep_n = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = [wrd_index.doc2bow(txt) for txt in tqdm(bow_txts)]\n",
    "# corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will determine which sentences to extract from the article's text by finding the cosine similarity between all tf-idf transformed sentences. The extracted sentences will have the highest average cosine similarity to the remaining sentences. By doing this, the summary should include sentences that show the highest importance to the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_similarities(text):\n",
    "#     sentences = preprocess_text(text)\n",
    "#     #vectorize sentences and remove stop words\n",
    "#     vectorizer = TfidfVectorizer()\n",
    "#     #transform using TFIDF vectorizer\n",
    "#     trsfm=vectorizer.fit_transform(sentences)\n",
    "    \n",
    "#     #creat df for input article\n",
    "#     text_df = pd.DataFrame(trsfm.toarray(),columns=vectorizer.get_feature_names(),index=sentences)\n",
    "    \n",
    "#     #declare how many sentences to use in summary\n",
    "#     num_sentences = text_df.shape[0]\n",
    "#     num_summary_sentences = int(np.ceil(num_sentences**.5))\n",
    "        \n",
    "#     #find cosine similarity for all sentence pairs\n",
    "#     similarities = cosine_similarity(trsfm, trsfm)\n",
    "    \n",
    "#     #create list to hold avg cosine similarities for each sentence\n",
    "#     avgs = []\n",
    "#     for i in similarities:\n",
    "#         avgs.append(i.mean())\n",
    "     \n",
    "#     #find index values of the sentences to be used for summary\n",
    "#     top_idx = np.argsort(avgs)[-num_summary_sentences:]\n",
    "    \n",
    "#     return top_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scikit Learn\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# import pandas as pd\n",
    "\n",
    "# # Create the Document Term Matrix\n",
    "# count_vectorizer = CountVectorizer()\n",
    "# sparse_matrix = count_vectorizer.fit_transform(df_list_base.text)\n",
    "# # Similarity between the first document (“Alpine snow winter boots”) with each of the other documents of the set:\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# cosine_similarity(sparse_matrix[0:1], sparse_matrix)\n",
    "# array([[ 0.50305744 ,  0.16651513,  0.62305744,  0.13448867]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list_test.text[0].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/bd9/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda/envs/bd9/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ix_new</th>\n",
       "      <th>ix_train</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2561</td>\n",
       "      <td>19</td>\n",
       "      <td>0.241531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.211504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0.297733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1111</td>\n",
       "      <td>19</td>\n",
       "      <td>0.107998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>522</td>\n",
       "      <td>19</td>\n",
       "      <td>0.101888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3084</td>\n",
       "      <td>19</td>\n",
       "      <td>0.090757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3090</td>\n",
       "      <td>19</td>\n",
       "      <td>0.193223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3343</td>\n",
       "      <td>19</td>\n",
       "      <td>0.174380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2968</td>\n",
       "      <td>19</td>\n",
       "      <td>0.126408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>534</td>\n",
       "      <td>19</td>\n",
       "      <td>0.284497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ix_new ix_train     score\n",
       "0   2561       19  0.241531\n",
       "1      4       19  0.211504\n",
       "2      5       19  0.297733\n",
       "3   1111       19  0.107998\n",
       "4    522       19  0.101888\n",
       "5   3084       19  0.090757\n",
       "6   3090       19  0.193223\n",
       "7   3343       19  0.174380\n",
       "8   2968       19  0.126408\n",
       "9    534       19  0.284497"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_tokenizer_score(new_series, train_series, tokenizer):\n",
    "    \"\"\"\n",
    "    return the tf idf score of each possible pairs of documents\n",
    "    Args:\n",
    "        new_series (pd.Series): new data (To compare against train data)\n",
    "        train_series (pd.Series): train data (To fit the tf-idf transformer)\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    train_tfidf = tokenizer.fit_transform(train_series)\n",
    "    new_tfidf = tokenizer.transform(new_series)\n",
    "    X = pd.DataFrame(cosine_similarity(new_tfidf, train_tfidf), columns=train_series.index)\n",
    "    X['ix_new'] = new_series.index\n",
    "    score = pd.melt(\n",
    "        X,\n",
    "        id_vars='ix_new',\n",
    "        var_name='ix_train',\n",
    "        value_name='score'\n",
    "    )\n",
    "    return score\n",
    "\n",
    "train_set = pd.Series(df_list_base.text)\n",
    "test_set = pd.Series(df_list_test.text)\n",
    "tokenizer = TfidfVectorizer(analyzer=preprocess_text) # initiate here your own tokenizer (TfidfVectorizer, CountVectorizer, with stopwords...)\n",
    "score = create_tokenizer_score(train_series=train_set, new_series=test_set, tokenizer=tokenizer)\n",
    "score.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ix_new</th>\n",
       "      <th>ix_train</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2561</td>\n",
       "      <td>19</td>\n",
       "      <td>0.241531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.211504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0.297733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1111</td>\n",
       "      <td>19</td>\n",
       "      <td>0.107998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>522</td>\n",
       "      <td>19</td>\n",
       "      <td>0.101888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3084</td>\n",
       "      <td>19</td>\n",
       "      <td>0.090757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3090</td>\n",
       "      <td>19</td>\n",
       "      <td>0.193223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3343</td>\n",
       "      <td>19</td>\n",
       "      <td>0.174380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2968</td>\n",
       "      <td>19</td>\n",
       "      <td>0.126408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>534</td>\n",
       "      <td>19</td>\n",
       "      <td>0.284497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2583</td>\n",
       "      <td>19</td>\n",
       "      <td>0.245077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>536</td>\n",
       "      <td>19</td>\n",
       "      <td>0.263706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2565</td>\n",
       "      <td>19</td>\n",
       "      <td>0.287581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2588</td>\n",
       "      <td>19</td>\n",
       "      <td>0.152605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2591</td>\n",
       "      <td>19</td>\n",
       "      <td>0.214044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2084</td>\n",
       "      <td>19</td>\n",
       "      <td>0.201040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2603</td>\n",
       "      <td>19</td>\n",
       "      <td>0.046091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1580</td>\n",
       "      <td>19</td>\n",
       "      <td>0.155645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2606</td>\n",
       "      <td>19</td>\n",
       "      <td>0.211944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1072</td>\n",
       "      <td>19</td>\n",
       "      <td>0.168312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1074</td>\n",
       "      <td>19</td>\n",
       "      <td>0.149065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>52</td>\n",
       "      <td>19</td>\n",
       "      <td>0.168407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2101</td>\n",
       "      <td>19</td>\n",
       "      <td>0.133912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>572</td>\n",
       "      <td>19</td>\n",
       "      <td>0.241030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2622</td>\n",
       "      <td>19</td>\n",
       "      <td>0.252148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>63</td>\n",
       "      <td>19</td>\n",
       "      <td>0.115677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2624</td>\n",
       "      <td>19</td>\n",
       "      <td>0.263976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3649</td>\n",
       "      <td>19</td>\n",
       "      <td>0.233578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1602</td>\n",
       "      <td>19</td>\n",
       "      <td>0.214065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>587</td>\n",
       "      <td>19</td>\n",
       "      <td>0.103240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2228</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1717</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2744</td>\n",
       "      <td>3</td>\n",
       "      <td>0.016687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>3468</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2238</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>3775</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>3264</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1218</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>3268</td>\n",
       "      <td>3</td>\n",
       "      <td>0.023524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>710</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3783</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>712</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1740</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2224</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1747</td>\n",
       "      <td>3</td>\n",
       "      <td>0.967703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>548</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>3285</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>724</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2682</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>3804</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1404</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2855</td>\n",
       "      <td>3</td>\n",
       "      <td>0.029666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>3925</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1806</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2259</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1779</td>\n",
       "      <td>3</td>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>3180</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3317</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>3318</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1273</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ix_new ix_train     score\n",
       "0     2561       19  0.241531\n",
       "1        4       19  0.211504\n",
       "2        5       19  0.297733\n",
       "3     1111       19  0.107998\n",
       "4      522       19  0.101888\n",
       "5     3084       19  0.090757\n",
       "6     3090       19  0.193223\n",
       "7     3343       19  0.174380\n",
       "8     2968       19  0.126408\n",
       "9      534       19  0.284497\n",
       "10    2583       19  0.245077\n",
       "11     536       19  0.263706\n",
       "12    2565       19  0.287581\n",
       "13    2588       19  0.152605\n",
       "14    2591       19  0.214044\n",
       "15    2084       19  0.201040\n",
       "16    2603       19  0.046091\n",
       "17    1580       19  0.155645\n",
       "18    2606       19  0.211944\n",
       "19    1072       19  0.168312\n",
       "20    1074       19  0.149065\n",
       "21      52       19  0.168407\n",
       "22    2101       19  0.133912\n",
       "23     572       19  0.241030\n",
       "24    2622       19  0.252148\n",
       "25      63       19  0.115677\n",
       "26    2624       19  0.263976\n",
       "27    3649       19  0.233578\n",
       "28    1602       19  0.214065\n",
       "29     587       19  0.103240\n",
       "..     ...      ...       ...\n",
       "270   2228        3  0.015864\n",
       "271   1717        3  0.000000\n",
       "272   2744        3  0.016687\n",
       "273   3468        3  0.000000\n",
       "274   2238        3  0.009347\n",
       "275   3775        3  0.000000\n",
       "276   3264        3  0.000000\n",
       "277   1218        3  0.000000\n",
       "278   3268        3  0.023524\n",
       "279    710        3  0.000000\n",
       "280   3783        3  0.000000\n",
       "281    712        3  0.000000\n",
       "282   1740        3  0.000000\n",
       "283   2224        3  0.000000\n",
       "284   1747        3  0.967703\n",
       "285    548        3  0.000000\n",
       "286   3285        3  0.004482\n",
       "287    724        3  0.000000\n",
       "288   2682        3  0.000000\n",
       "289   3804        3  0.000000\n",
       "290   1404        3  0.000000\n",
       "291   2855        3  0.029666\n",
       "292   3925        3  0.000000\n",
       "293   1806        3  0.000000\n",
       "294   2259        3  0.000000\n",
       "295   1779        3  0.006877\n",
       "296   3180        3  0.000000\n",
       "297   3317        3  0.007759\n",
       "298   3318        3  0.000000\n",
       "299   1273        3  0.000000\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ix_new</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>1.613293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>2.996213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>2.353618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1.252495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>1.767176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>3.887458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>3.091197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>3.650625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1.658839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2.154749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score\n",
       "ix_new          \n",
       "1024    1.613293\n",
       "1072    2.996213\n",
       "1074    2.353618\n",
       "1111    1.252495\n",
       "1115    1.767176\n",
       "1125    3.887458\n",
       "1137    3.091197\n",
       "1152    3.650625\n",
       "1166    1.658839\n",
       "1200    2.154749"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cos = score.groupby(['ix_new']).sum()\n",
    "df_cos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.558896108000889"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Находим среднее значение\n",
    "m = df_cos['score'].mean()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defined = (df_cos[df_cos['score']>=m].index.values.astype(int))\n",
    "defined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = (df_cos[df_cos['score']<m].index.values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json import JSONEncoder\n",
    "import numpy\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, numpy.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyData = {\"defined\": defined, \"other\": other}\n",
    "# encodedNumpyData = json.dumps(numpyData, cls=NumpyArrayEncoder)  # use dump() to write array into file\n",
    "with open(\"../lab05.json\", \"w\") as write_file:\n",
    "    json.dump(numpyData, write_file, cls=NumpyArrayEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : &(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of TfidfVectorizer\n",
    "# vectoriser = TfidfVectorizer(analyzer=preprocess_text)\n",
    "# # Fit to the data and transform to feature matrix\n",
    "# X_train = vectoriser.fit_transform(X_train['speech'])\n",
    "# # Convert sparse matrix to dataframe\n",
    "# X_train = pd.DataFrame.sparse.from_spmatrix(X_train)\n",
    "# # Save mapping on which index refers to which words\n",
    "# col_map = {v:k for k, v in vectoriser.vocabulary_.items()}\n",
    "# Rename each column using the mapping\n",
    "# for col in X_train.columns:\n",
    "#     X_train.rename(columns={col: col_map[col]}, inplace=True)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
