Очень понравилось само решение. Есть несколько замечаний которые больше касаются python нежели DS

```python
# Если в переменной более 75тыс пустых строк - считаем ее бесполезной и выкидываем

for col in (df2.columns.tolist()):
    if df2[col].isnull().sum()>75000:
        df2=df2.drop(col,axis=1)
```

Если бы наша выборка была больше, то учитывая колличество удаленных столбцов, код бы очень сильно тормозил. Оптимальнее было бы сложить имена всех колонок в один лист и затем уже одним вызовом дропать. Так будет работать быстрее.

```python
for col in columns_float:
    df_final[col]=df_final[col].fillna(df_final[col].dropna().mean())
for col in columns_bins:
    df_final[col]=df_final[col].fillna(df_final[col].dropna().mean())
```
Возможно всю предобработку исходных данных имело смысл положить внутрь функции, что бы один код чистил train и test.