{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимы модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:27:42.833843Z",
     "start_time": "2020-11-13T13:27:42.086992Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import pymorphy2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем, что сколько базовых документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:27:44.854600Z",
     "start_time": "2020-11-13T13:27:44.613959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 bubl bubl 2.9K Oct 25 21:34 /data/share/lab05data/base_10.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 3.0K Oct 25 21:34 /data/share/lab05data/base_11.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 2.6K Oct 25 21:34 /data/share/lab05data/base_12.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 2.6K Oct 25 21:34 /data/share/lab05data/base_13.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 9.2K Oct 25 21:34 /data/share/lab05data/base_14.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 2.9K Oct 25 21:34 /data/share/lab05data/base_15.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 3.6K Oct 25 21:34 /data/share/lab05data/base_16.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 3.8K Oct 25 21:34 /data/share/lab05data/base_17.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 4.2K Oct 25 21:34 /data/share/lab05data/base_18.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 3.7K Oct 25 21:34 /data/share/lab05data/base_19.txt\r\n",
      "-rw-r--r-- 1 bubl bubl  803 Oct 25 21:34 /data/share/lab05data/base_1.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 3.0K Oct 25 21:34 /data/share/lab05data/base_20.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 2.1K Oct 25 21:34 /data/share/lab05data/base_2.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 2.0K Oct 25 21:33 /data/share/lab05data/base_3.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 6.4K Oct 25 21:34 /data/share/lab05data/base_4.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 1.5K Oct 25 21:33 /data/share/lab05data/base_5.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 3.0K Oct 25 21:34 /data/share/lab05data/base_6.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 1.7K Oct 25 21:33 /data/share/lab05data/base_7.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 2.9K Oct 25 21:34 /data/share/lab05data/base_8.txt\r\n",
      "-rw-r--r-- 1 bubl bubl 2.9K Oct 25 21:34 /data/share/lab05data/base_9.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah /data/share/lab05data/base*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем \"базовые\" тексты в датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:27:47.337263Z",
     "start_time": "2020-11-13T13:27:47.279795Z"
    }
   },
   "outputs": [],
   "source": [
    "base_filemask = '/data/share/lab05data/base_{}.txt'\n",
    "train_df = pd.DataFrame(columns=['id', 'text'])\n",
    "for i in range(1, 21):\n",
    "    base_filename = base_filemask.format(i)\n",
    "    with open(base_filename, 'r') as file:\n",
    "        train_df = train_df.append({'id': i, 'text': file.readline()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:27:48.890132Z",
     "start_time": "2020-11-13T13:27:48.871485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;Ищем прекрасного программиста 1С в дружный ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;p&gt;Предлагаем уникальную возможность присоедин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;p&gt;NetCracker Technology Corp., a large softwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Senior Java software engineer в Отд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;NetCracker Technology Corp., a large softwa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                               text\n",
       "0  1  <p>Ищем прекрасного программиста 1С в дружный ...\n",
       "1  2  <p>Предлагаем уникальную возможность присоедин...\n",
       "2  3  <p>NetCracker Technology Corp., a large softwa...\n",
       "3  4  <p><strong>Senior Java software engineer в Отд...\n",
       "4  5  <p>NetCracker Technology Corp., a large softwa..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем тексты, по которым необходимо определить сходство с базовыми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:27:51.916832Z",
     "start_time": "2020-11-13T13:27:51.441715Z"
    }
   },
   "outputs": [],
   "source": [
    "test_filemask = '/data/share/lab05data/test_{}.txt'\n",
    "ids = [2049, 5, 1740, 3593, 3085, 3086, 3600, 1553, 2067, 22, 3607, 536, 25, 538, 3612, \n",
    "       2079, 2592, 2084, 1232, 2602, 3627, 1072, 777, 1076, 3125, 56, 570, 572, 1599, \n",
    "       3649, 1602, 2628, 1608, 586, 587, 78, 1550, 3665, 85, 89, 1626, 1115, 1131, 1647, \n",
    "       2676, 633, 1658, 2174, 1152, 1710, 3715, 2692, 645, 646, 1160, 1674, 3212, 3730, \n",
    "       1174, 2200, 3738, 1692, 1695, 1188, 1302, 678, 3239, 174, 1200, 177, 3763, 180, \n",
    "       3253, 2230, 2744, 1209, 1723, 701, 1214, 1217, 196, 887, 3272, 3788, 2582, 2255, \n",
    "       720, 3795, 1748, 1146, 2265, 1244, 1759, 3808, 3299, 3300, 3818, 3822, 241, 1269, \n",
    "       1270, 2688, 1277, 766, 2816, 3842, 262, 1289, 3850, 3340, 3343, 275, 2326, 1305, \n",
    "       2332, 1311, 3362, 3292, 808, 298, 2861, 2350, 3375, 2526, 2355, 822, 301, 1849, \n",
    "       3387, 1347, 1860, 3398, 3913, 2386, 3925, 2902, 3415, 2618, 869, 2918, 2450, \n",
    "       3433, 2411, 3438, 1911, 888, 383, 1920, 2436, 2950, 907, 909, 1423, 1936, 1425, \n",
    "       402, 836, 3067, 2457, 496, 2973, 414, 2374, 1441, 2467, 668, 1961, 1963, 943, \n",
    "       2377, 2634, 3001, 2492, 3007, 3009, 450, 1991, 2504, 971, 3030, 3545, 3547, \n",
    "       1616, 989, 1019, 479, 482, 2812, 307, 2030, 1519, 3052, 498, 2035, 1262, 503, \n",
    "       504, 2043, 2044, 3564]\n",
    "\n",
    "test_df = pd.DataFrame(columns=['id', 'text'])\n",
    "for i in ids:\n",
    "    test_filename = test_filemask.format(i)\n",
    "    with open(test_filename, 'r') as file:\n",
    "        test_df = test_df.append({'id': i, 'text': file.readline()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:27:53.066331Z",
     "start_time": "2020-11-13T13:27:53.057260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Чем придется заниматься:&lt;/strong&gt;&lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1740</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Мы предлагаем всё и сразу: &lt;/strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3593</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Специалист по товародвижению в ночн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3085</td>\n",
       "      <td>&lt;p&gt;Компания РосДеньги – надёжная федеральная м...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text\n",
       "0  2049  <p><strong>Чем придется заниматься:</strong></...\n",
       "1     5  <p><strong>Обязанности:</strong></p> <ul> <li>...\n",
       "2  1740  <p><strong>Мы предлагаем всё и сразу: </strong...\n",
       "3  3593  <p><strong>Специалист по товародвижению в ночн...\n",
       "4  3085  <p>Компания РосДеньги – надёжная федеральная м..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем свой токенизатор. Можно было еще использовать beautifulsoup для удаления тегов, но понял это уже после выполнения заданич"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Да, beautifulsoup помог бы избавиться от тегов и их атрибутов. Например, видно, что в тексты попало много слов \"strong\" - это тэг, который делает шрифт жирным. Хотя, может быть, он тоже сыграл какую-нибудь положительную роль :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Используется регулярное выражение `([^\\w]|[+])`. То есть любой символ, который не является буквой, цифрой или знаком подчеркивания (в нашем случае `\\w = [a-zA-Zа-яА-Я_]`) или является знаком плюс (`[+]`) будет рассмотрен в качестве разделителя. Знак плюс в данном случае избыточен, т.к. он уже входит в паттерн `[^\\w]`. `t.isspace()` скорей всего тоже не сыграет никакой роли, т.к. все пробельные символы будут исключены, т.к. они будут рассмотрены в качестве разделителя.**\n",
    "\n",
    "**Раз уж тут используется лемматизатор для русских слов, можно было бы еще использовать лемматизатор для английских слов для симметрии :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:27:56.745647Z",
     "start_time": "2020-11-13T13:27:55.978341Z"
    }
   },
   "outputs": [],
   "source": [
    "GROUPING_SPACE_REGEX = re.compile(r'([^\\w]|[+])', re.UNICODE)\n",
    "def simple_word_tokenize(text, _split=GROUPING_SPACE_REGEX.split):\n",
    "    return [t for t in _split(text.lower()) if t and not t.isspace() and len(t) > 2]\n",
    "\n",
    "m = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def token_r(text):\n",
    "    words = simple_word_tokenize(text)\n",
    "    return [m.parse(x)[0].normal_form for x in words]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stops_english = set(stopwords.words('english'))\n",
    "stops_russian = set(stopwords.words('russian'))\n",
    "stop = stops_english | stops_russian\n",
    "\n",
    "cv = CountVectorizer(tokenizer=token_r, stop_words=stop, ngram_range=(1,2), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:43:28.890611Z",
     "start_time": "2020-11-13T13:43:28.880492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function SRE_Pattern.split(string=None, maxsplit=0, *, source=None)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GROUPING_SPACE_REGEX.split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:43:48.947162Z",
     "start_time": "2020-11-13T13:43:48.149800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None,\n",
       "        stop_words={'didn', 'об', \"you're\", 'through', 'doesn', 'ни', 'даже', 'уж', 'the', 'один', 'при', 'yourselves', 'which', 'же', 'этом', 'больше', \"she's\", 'mightn', 'два', 'off', 'did', 'once', 'our', 'но', \"doesn't\", 'такой', 'were', 'hasn', 'без', 'most', 'себя', 'потом', 'these', 'but', 'можно', '..., 'сам', 'над', 'какой', 'уже', 'about', 'whom', 'была', 'мне', 'should', 'тут', 'о', 'все', 'then'},\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function token_r at 0x7f7fbbad29d8>, vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(train_df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сотрим, что за фичи получились"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:43:54.037156Z",
     "start_time": "2020-11-13T13:43:54.021971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100',\n",
       " '100 таблица',\n",
       " '100 это',\n",
       " '300',\n",
       " '300 строка',\n",
       " 'abilities',\n",
       " 'abilities business',\n",
       " 'ability',\n",
       " 'ability interact',\n",
       " 'ability travel']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем наши \"базовые\" документы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**До этого CountVectorizer уже был обучен, тут можно было применить только cv.transform. А то получается, что мы заново тут его обучаем**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:44:16.806830Z",
     "start_time": "2020-11-13T13:44:16.085931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 715 ms, sys: 0 ns, total: 715 ms\n",
      "Wall time: 716 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_matrix = cv.fit_transform(train_df.text).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим топ слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вот оно топ слово из тэга `<strong>` :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:46:24.264479Z",
     "start_time": "2020-11-13T13:46:24.253681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('strong', 19),\n",
       " ('работа', 17),\n",
       " ('команда', 16),\n",
       " ('разработка', 16),\n",
       " ('знание', 16),\n",
       " ('опыт', 16),\n",
       " ('компания', 15),\n",
       " ('разработчик', 14),\n",
       " ('требование', 14),\n",
       " ('опыт разработка', 14),\n",
       " ('опыт работа', 13),\n",
       " ('strong strong', 13),\n",
       " ('решение', 13),\n",
       " ('результат', 13),\n",
       " ('проект', 12),\n",
       " ('свой', 12),\n",
       " ('strong требование', 12),\n",
       " ('наш', 11),\n",
       " ('продукт', 11),\n",
       " ('понимание', 11)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_words = base_matrix.sum(axis=0)\n",
    "words_freq = [(word, sum_words[idx]) for word, idx in cv.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "words_freq[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем \"тестовые\" документы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:46:37.304349Z",
     "start_time": "2020-11-13T13:46:31.785788Z"
    }
   },
   "outputs": [],
   "source": [
    "test_matrix = cv.transform(test_df.text).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим косинусное сходство между \"тестовыми\" и \"базовыми\" документами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:47:02.462115Z",
     "start_time": "2020-11-13T13:47:02.292955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07906198, 0.08959404, 0.04702304, ..., 0.09153773, 0.01280684,\n",
       "        0.02036157],\n",
       "       [0.18943817, 0.12281814, 0.09100315, ..., 0.20667725, 0.22306433,\n",
       "        0.15762208],\n",
       "       [0.01133695, 0.01124128, 0.01179987, ..., 0.02871288, 0.01928234,\n",
       "        0.01021899],\n",
       "       ...,\n",
       "       [0.21540966, 0.1898594 , 0.09964688, ..., 0.15518264, 0.18997346,\n",
       "        0.16396378],\n",
       "       [0.16642306, 0.22690061, 0.10826163, ..., 0.17386733, 0.2063972 ,\n",
       "        0.19689038],\n",
       "       [0.17250998, 0.22623294, 0.09267307, ..., 0.15785235, 0.25870726,\n",
       "        0.19061093]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_m = cosine_similarity(base_matrix, test_matrix)\n",
    "cos_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суммируем косинусную близость по каждому тестовому документу и считаем среднее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:47:41.913105Z",
     "start_time": "2020-11-13T13:47:41.906697Z"
    }
   },
   "outputs": [],
   "source": [
    "cos_m_sum = np.sum(cos_m, axis=0)\n",
    "test_df['def'] = cos_m_sum > cos_m_sum.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим, что же получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:47:46.290931Z",
     "start_time": "2020-11-13T13:47:46.279930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2049</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Чем придется заниматься:&lt;/strong&gt;&lt;/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1740</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Мы предлагаем всё и сразу: &lt;/strong...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3593</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Специалист по товародвижению в ночн...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3085</td>\n",
       "      <td>&lt;p&gt;Компания РосДеньги – надёжная федеральная м...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text    def\n",
       "0  2049  <p><strong>Чем придется заниматься:</strong></...   True\n",
       "1     5  <p><strong>Обязанности:</strong></p> <ul> <li>...   True\n",
       "2  1740  <p><strong>Мы предлагаем всё и сразу: </strong...  False\n",
       "3  3593  <p><strong>Специалист по товародвижению в ночн...  False\n",
       "4  3085  <p>Компания РосДеньги – надёжная федеральная м...   True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:47:57.101143Z",
     "start_time": "2020-11-13T13:47:57.092748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    101\n",
       "True      99\n",
       "Name: def, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['def'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формируем ответ для чекера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T13:48:13.587172Z",
     "start_time": "2020-11-13T13:48:13.579946Z"
    }
   },
   "outputs": [],
   "source": [
    "answer = {\n",
    "    'defined': test_df[test_df['def']].id.tolist(),\n",
    "    'other': test_df[~test_df['def']].id.tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/home/alexander.alexandrov/lab05.json', 'w') as outfile:\n",
    "    json.dump(answer, outfile)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
